{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79929078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for Prediction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9292655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset by assining into variables\n",
    "df=pd.read_excel('Losses.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2517b521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>MONTH_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>GROSS INCURRED AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>477.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>139.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>548.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY    MONTH  MONTH_ID    YEAR      CAUSE  GROSS INCURRED AMOUNT\n",
       "0  1.0  January       1.0  1999.0  WINDSTORM                 477.88\n",
       "1  1.0  January       1.0  1999.0       FIRE                 700.00\n",
       "2  1.0  January       1.0  1999.0  WINDSTORM                  99.87\n",
       "3  1.0  January       1.0  1999.0  WINDSTORM                 139.80\n",
       "4  1.0  January       1.0  1999.0  WINDSTORM                 548.66"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the 5 records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469fd2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47565, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the No. of Rows and Columns in dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31893f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here in dataset MONTH_ID is not Required as Month and MONTH_ID Refers the Same\n",
    "df.drop('MONTH_ID',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25017321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CAUSE</th>\n",
       "      <th>GROSS INCURRED AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>477.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>FIRE</td>\n",
       "      <td>700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>139.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>January</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>WINDSTORM</td>\n",
       "      <td>548.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY    MONTH    YEAR      CAUSE  GROSS INCURRED AMOUNT\n",
       "0  1.0  January  1999.0  WINDSTORM                 477.88\n",
       "1  1.0  January  1999.0       FIRE                 700.00\n",
       "2  1.0  January  1999.0  WINDSTORM                  99.87\n",
       "3  1.0  January  1999.0  WINDSTORM                 139.80\n",
       "4  1.0  January  1999.0  WINDSTORM                 548.66"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross check  the dataset MONTH_ID has been deleted or not\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f27868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47565 entries, 0 to 47564\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   DAY                    47565 non-null  float64\n",
      " 1   MONTH                  47565 non-null  object \n",
      " 2   YEAR                   47565 non-null  float64\n",
      " 3   CAUSE                  47565 non-null  object \n",
      " 4   GROSS INCURRED AMOUNT  47565 non-null  float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check the Description of dataset with columns Properties\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8107315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY                      0\n",
       "MONTH                    0\n",
       "YEAR                     0\n",
       "CAUSE                    0\n",
       "GROSS INCURRED AMOUNT    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values in dataset\n",
    "df.isnull().sum()\n",
    "\n",
    "#here Values in each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb8e1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY                      float64\n",
       "MONTH                     object\n",
       "YEAR                     float64\n",
       "CAUSE                     object\n",
       "GROSS INCURRED AMOUNT    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross check with data types for null values\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879ef767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualise for null values in dataset\n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()\n",
    "\n",
    "#Here no Null through Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cbb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here We will not delete the duplicate values as there might be having similar policy claim amount on same time and same day\n",
    "as the chances of calamities and harmness be on the same day itself\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f92fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the for prediction through deep learning required the values in single units so we will apply LabelEncoder for Object types Columns\n",
    "#Seperate the numeric and object type data\n",
    "df_num=df.select_dtypes('float64')\n",
    "df_cat=df.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44499aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply LabelEncoder on Categorical Columns\n",
    "from sklearn.preprocessing import LabelEncoder   #Call class of LabelEncoder()\n",
    "le=LabelEncoder()  #Create a variable for LabelEncoder()\n",
    "columns=df_cat.columns\n",
    "for col in columns:\n",
    "  df_cat[col]=le.fit_transform(df_cat[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf4d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concate both Object type and Numeric Type Colunms\n",
    "df_new=pd.concat([df_num,df_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e2779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>GROSS INCURRED AMOUNT</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CAUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>477.88</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>99.87</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>139.80</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>548.66</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAY    YEAR  GROSS INCURRED AMOUNT  MONTH  CAUSE\n",
       "0  1.0  1999.0                 477.88      4      7\n",
       "1  1.0  1999.0                 700.00      4      3\n",
       "2  1.0  1999.0                  99.87      4      7\n",
       "3  1.0  1999.0                 139.80      4      7\n",
       "4  1.0  1999.0                 548.66      4      7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the Concated Data\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e74cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualise types of Causes and check whether data is balanced or not, if not then we will have t0 balance data  \n",
    "plt.figure(figsize=(15,6))\n",
    "sb.countplot(data=df,x='CAUSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c942d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output\n",
    "X=df_new.drop('CAUSE',axis=1)\n",
    "Y=df_new['CAUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da741b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 70% for training and 30% for Testing Ratio\n",
    "from sklearn.model_selection import train_test_split  #Call model for train_test_split \n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c8445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply StandardScaler for converting into single unit dataset values before prediction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce4b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c27405b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    5398\n",
       "0    5398\n",
       "7    5398\n",
       "4    5398\n",
       "2    5398\n",
       "3    5398\n",
       "5    5398\n",
       "1    5398\n",
       "Name: CAUSE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we perform data balancing as our dataset is unbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#apply data balancing on training and testing data\n",
    "X_train1,Y_train1=SMOTE().fit_resample(X_train,Y_train)\n",
    "X_test1,Y_test1=SMOTE().fit_resample(X_test,Y_test)\n",
    "\n",
    "#check data balancing\n",
    "Y_test1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e85d2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7    12595\n",
       " 3    12595\n",
       " 4    12595\n",
       " 0    12595\n",
       " 2    12595\n",
       " 6    12595\n",
       " 5    12595\n",
       " 1    12595\n",
       " Name: CAUSE, dtype: int64,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05841634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user defined function as it easy to write run the model without writing 4 lines codes again and again \n",
    "def create_model(model):\n",
    "    model.fit(X_train1,Y_train1)\n",
    "    Y_pred=model.predict(X_test1)\n",
    "    print(classification_report(Y_test1,Y_pred))\n",
    "    print(confusion_matrix(Y_test1,Y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf72b0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ecff7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.34      0.27      5398\n",
      "           1       0.72      0.92      0.81      5398\n",
      "           2       0.26      0.49      0.34      5398\n",
      "           3       0.22      0.05      0.08      5398\n",
      "           4       0.26      0.47      0.33      5398\n",
      "           5       0.41      0.39      0.40      5398\n",
      "           6       0.17      0.02      0.04      5398\n",
      "           7       0.10      0.02      0.03      5398\n",
      "\n",
      "    accuracy                           0.34     43184\n",
      "   macro avg       0.30      0.34      0.29     43184\n",
      "weighted avg       0.30      0.34      0.29     43184\n",
      "\n",
      "[[1862  346 1173   36 1321  399   96  165]\n",
      " [  43 4988    0    0  273   85    9    0]\n",
      " [1228  112 2663  180  415  568   83  149]\n",
      " [ 926  290 1808  256 1156  719   83  160]\n",
      " [1158  480  185  178 2546  521  155  175]\n",
      " [ 435  194 1047  320 1007 2126   91  178]\n",
      " [1346  394 1503  133 1406  357  118  141]\n",
      " [1257  163 1684   57 1724  349   51  113]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with LogisticRegression algorithm\n",
    "from sklearn.linear_model import LogisticRegression                   #call the class\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "lr=LogisticRegression(random_state=1)\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59178c7f",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc252933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.37      0.31      5398\n",
      "           1       0.95      0.81      0.88      5398\n",
      "           2       0.28      0.26      0.27      5398\n",
      "           3       0.25      0.24      0.25      5398\n",
      "           4       0.30      0.29      0.30      5398\n",
      "           5       0.46      0.30      0.36      5398\n",
      "           6       0.20      0.22      0.21      5398\n",
      "           7       0.46      0.50      0.48      5398\n",
      "\n",
      "    accuracy                           0.38     43184\n",
      "   macro avg       0.40      0.38      0.38     43184\n",
      "weighted avg       0.40      0.38      0.38     43184\n",
      "\n",
      "[[2022   12  626  334  695  123  939  647]\n",
      " [ 159 4398   47  147  379  113  115   40]\n",
      " [1116   23 1414  729  283  358  946  529]\n",
      " [ 734   83  773 1319  620  649  742  478]\n",
      " [1084   10  327  634 1568  255  921  599]\n",
      " [ 658   87  528 1201  444 1622  519  339]\n",
      " [1334   10  762  641  702  239 1179  531]\n",
      " [ 752    8  510  309  466  176  482 2695]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Gini index \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(random_state=1)\n",
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf2754",
   "metadata": {},
   "source": [
    "# Pruning technique with Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ad31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxdepth Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f780c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.44      0.34      5398\n",
      "           1       0.90      0.82      0.85      5398\n",
      "           2       0.29      0.48      0.36      5398\n",
      "           3       0.24      0.18      0.20      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.47      0.50      0.49      5398\n",
      "           6       0.09      0.00      0.01      5398\n",
      "           7       0.61      0.35      0.45      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.40      0.40      0.38     43184\n",
      "weighted avg       0.40      0.40      0.38     43184\n",
      "\n",
      "[[2379   49 1291  272  836  266   42  263]\n",
      " [ 136 4411   29  146  537   80   19   40]\n",
      " [1048  149 2589  636  111  730   13  122]\n",
      " [ 809  115 1563  954  903  932   29   93]\n",
      " [1416    3  204  448 2340  442   27  518]\n",
      " [ 254   77  645  829  847 2706   26   14]\n",
      " [1609   65 1562  470 1252  236   17  187]\n",
      " [ 997   55 1106  266  744  320    8 1902]]\n"
     ]
    }
   ],
   "source": [
    "#max_depth pruning technique on DecisionTreeClassifier with Gini index\n",
    "#max depth= 9 gives best f1-score\n",
    "dtc_max_depth=DecisionTreeClassifier(max_depth=8,random_state=1)\n",
    "dtc_max_depth=create_model(dtc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min_sample_leaf with  Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "719748d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.36      0.34      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.37      0.34      5398\n",
      "           5       0.40      0.44      0.42      5398\n",
      "           6       0.19      0.14      0.16      5398\n",
      "           7       0.56      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1464   22  871  534  912  307  785  503]\n",
      " [  35 4518   46  141  406  187   57    8]\n",
      " [ 566   40 1939  864  271  712  631  375]\n",
      " [ 408   77  956 1494  627 1017  541  278]\n",
      " [ 689   25  299  711 2002  591  593  488]\n",
      " [ 169   60  478 1333  569 2402  282  105]\n",
      " [ 985   37  956  874  993  403  764  386]\n",
      " [ 463   11  615  351  572  315  373 2698]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.28      0.25      5398\n",
      "           4       0.32      0.37      0.34      5398\n",
      "           5       0.40      0.44      0.42      5398\n",
      "           6       0.19      0.14      0.16      5398\n",
      "           7       0.56      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1448   17  883  525  916  306  796  507]\n",
      " [  35 4518   42  152  390  196   57    8]\n",
      " [ 581   39 1905  868  264  702  654  385]\n",
      " [ 408   77  938 1487  638 1026  541  283]\n",
      " [ 681   25  305  683 2018  588  604  494]\n",
      " [ 172   60  452 1397  575 2399  238  105]\n",
      " [ 976   37  971  863  999  399  768  385]\n",
      " [ 452   12  627  328  568  322  380 2709]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.38      0.35      5398\n",
      "           5       0.41      0.44      0.42      5398\n",
      "           6       0.19      0.15      0.17      5398\n",
      "           7       0.56      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1438   17  884  513  932  299  807  508]\n",
      " [  35 4518   42  155  387  196   57    8]\n",
      " [ 598   40 1889  882  280  673  646  390]\n",
      " [ 398   77  935 1503  642 1031  526  286]\n",
      " [ 664   25  291  682 2044  583  626  483]\n",
      " [ 170   60  445 1423  576 2382  235  107]\n",
      " [ 962   38  976  861 1009  390  788  374]\n",
      " [ 459   12  634  320  573  321  374 2705]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.31      0.34      0.32      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.32      0.38      0.35      5398\n",
      "           5       0.41      0.45      0.42      5398\n",
      "           6       0.20      0.15      0.17      5398\n",
      "           7       0.56      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1455   17  875  522  937  309  774  509]\n",
      " [  35 4525   36  154  387  196   57    8]\n",
      " [ 619   41 1820  897  286  683  660  392]\n",
      " [ 443   94  896 1472  631 1059  514  289]\n",
      " [ 649   33  295  682 2046  571  632  490]\n",
      " [ 171   71  447 1398  576 2405  226  104]\n",
      " [ 974   43  950  876 1005  387  785  378]\n",
      " [ 469   14  601  338  567  315  376 2718]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.32      0.38      0.35      5398\n",
      "           5       0.41      0.44      0.43      5398\n",
      "           6       0.20      0.14      0.17      5398\n",
      "           7       0.56      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1510   17  873  517  926  307  746  502]\n",
      " [  46 4525   42  148  376  196   57    8]\n",
      " [ 650   41 1871  890  261  671  645  369]\n",
      " [ 456   94  912 1472  633 1042  500  289]\n",
      " [ 697   33  282  701 2046  557  580  502]\n",
      " [ 181   71  488 1377  592 2396  206   87]\n",
      " [1027   43  939  861  995  380  772  381]\n",
      " [ 475   14  622  328  570  313  360 2716]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.39      0.35      5398\n",
      "           5       0.41      0.45      0.43      5398\n",
      "           6       0.20      0.15      0.17      5398\n",
      "           7       0.57      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1492   17  880  516  941  303  761  488]\n",
      " [  46 4525   42  148  376  196   57    8]\n",
      " [ 633   41 1888  877  262  670  646  381]\n",
      " [ 453   94  946 1462  644 1045  510  244]\n",
      " [ 681   33  278  695 2087  536  619  469]\n",
      " [ 167   71  490 1328  619 2436  201   86]\n",
      " [1043   43  923  843 1017  374  791  364]\n",
      " [ 464   14  630  331  590  321  362 2686]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.32      0.39      0.35      5398\n",
      "           5       0.41      0.45      0.43      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.57      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1465   17  878  538  976  312  719  493]\n",
      " [  46 4525   42  148  376  196   57    8]\n",
      " [ 658   41 1848  893  257  691  651  359]\n",
      " [ 450   94 1003 1468  635 1028  489  231]\n",
      " [ 674   33  269  732 2095  548  562  485]\n",
      " [ 152   71  518 1331  629 2439  177   81]\n",
      " [1008   43  931  884 1029  385  742  376]\n",
      " [ 485   14  612  329  578  329  369 2682]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.32      0.39      0.35      5398\n",
      "           5       0.41      0.45      0.43      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.57      0.50      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1460   17  890  540  966  312  720  493]\n",
      " [  46 4525   45  148  379  190   57    8]\n",
      " [ 666   42 1847  884  255  696  650  358]\n",
      " [ 465   94 1009 1468  654  995  482  231]\n",
      " [ 659   33  289  719 2106  535  564  493]\n",
      " [ 165   71  527 1312  632 2416  194   81]\n",
      " [1018   43  927  876 1035  379  744  376]\n",
      " [ 490   14  626  336  586  315  350 2681]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.26      0.28      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.43      0.46      0.44      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1429   18  914  535  994  317  719  472]\n",
      " [  46 4525   45  147  380  190   57    8]\n",
      " [ 651   42 1885  857  274  691  655  343]\n",
      " [ 477   94 1074 1471  686  938  458  200]\n",
      " [ 649   45  280  733 2126  530  570  465]\n",
      " [ 137   69  528 1231  650 2506  195   82]\n",
      " [ 984   43  977  884 1059  377  742  332]\n",
      " [ 474   18  646  348  589  323  363 2637]]\n",
      "Min_samples_leaf : 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1403   18  920  541 1001  325  722  468]\n",
      " [  46 4526   45  135  391  190   57    8]\n",
      " [ 663   42 1887  866  271  699  633  337]\n",
      " [ 474   94 1064 1462  713  945  445  201]\n",
      " [ 601   43  284  742 2158  527  587  456]\n",
      " [ 140   69  518 1219  663 2532  176   81]\n",
      " [ 963   42  967  906 1073  376  738  333]\n",
      " [ 464   15  631  348  608  323  365 2644]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.42      0.46      0.44      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1403   18  932  522 1009  322  719  473]\n",
      " [  46 4531   45  131  391  189   57    8]\n",
      " [ 663   44 1919  842  272  689  632  337]\n",
      " [ 478   97 1072 1464  691  943  452  201]\n",
      " [ 597   44  300  730 2164  523  581  459]\n",
      " [ 131   70  522 1247  684 2487  172   85]\n",
      " [ 945   42  978  888 1068  372  752  353]\n",
      " [ 466   17  631  343  602  327  356 2656]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.17      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.41     43184\n",
      "weighted avg       0.41      0.40      0.41     43184\n",
      "\n",
      "[[1428   22  932  510  998  322  725  461]\n",
      " [  56 4528   38  140  374  189   65    8]\n",
      " [ 666   39 1927  845  274  674  639  334]\n",
      " [ 485   95 1082 1444  702  946  450  194]\n",
      " [ 600   42  299  715 2200  523  571  448]\n",
      " [ 141   69  517 1202  688 2530  164   87]\n",
      " [ 953   49  994  881 1058  358  757  348]\n",
      " [ 471   15  643  337  599  329  351 2653]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.40      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.21      0.14      0.16      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.41     43184\n",
      "weighted avg       0.41      0.40      0.41     43184\n",
      "\n",
      "[[1467   22  915  525 1001  320  705  443]\n",
      " [  56 4529   38  138  374  189   65    9]\n",
      " [ 701   39 1936  856  288  680  588  310]\n",
      " [ 471  111 1079 1437  697  949  463  191]\n",
      " [ 620   57  300  695 2184  543  544  455]\n",
      " [ 138  115  522 1158  675 2553  152   85]\n",
      " [ 979   56  981  884 1039  377  738  344]\n",
      " [ 478   19  645  344  597  332  341 2642]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.21      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1452   23  910  514 1013  325  716  445]\n",
      " [  56 4564   38  139  374  153   65    9]\n",
      " [ 682   34 1952  846  289  678  587  330]\n",
      " [ 446  116 1067 1430  719  952  476  192]\n",
      " [ 619   62  297  700 2201  548  516  455]\n",
      " [ 142  113  512 1185  666 2521  153  106]\n",
      " [1004   66  972  866 1041  368  738  343]\n",
      " [ 465   16  653  339  604  335  344 2642]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.46      0.44      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1429   27  914  521 1021  329  709  448]\n",
      " [  46 4563   38  137  380  156   69    9]\n",
      " [ 660   41 1967  831  297  677  599  326]\n",
      " [ 439  109 1096 1446  675  958  498  177]\n",
      " [ 598   62  291  704 2191  548  540  464]\n",
      " [ 129  102  549 1173  664 2505  169  107]\n",
      " [ 981   73  971  876 1023  376  746  352]\n",
      " [ 444   16  659  347  595  338  348 2651]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.40      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1398   26  900  547 1045  335  707  440]\n",
      " [  46 4563   45  129  381  156   69    9]\n",
      " [ 650   40 1931  847  302  705  617  306]\n",
      " [ 459  109 1041 1497  670  956  491  175]\n",
      " [ 594   52  290  695 2183  543  563  478]\n",
      " [ 129  102  552 1178  661 2526  167   83]\n",
      " [ 977   72  947  891 1032  374  751  354]\n",
      " [ 436   11  652  352  591  342  360 2654]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.40      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.17      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1391   26  909  548 1042  324  716  442]\n",
      " [  46 4575   45  114  382  158   69    9]\n",
      " [ 651   40 1939  844  297  703  621  303]\n",
      " [ 458  118 1023 1469  668  984  501  177]\n",
      " [ 600   57  299  698 2182  537  565  460]\n",
      " [ 135  121  552 1126  660 2558  163   83]\n",
      " [ 973   74  949  890 1040  362  758  352]\n",
      " [ 444   12  653  351  594  333  359 2652]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.17      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1375   26  914  538 1044  323  725  453]\n",
      " [  46 4575   45  114  384  156   69    9]\n",
      " [ 643   40 1930  846  300  705  635  299]\n",
      " [ 446  117 1018 1453  681  991  509  183]\n",
      " [ 594   57  305  679 2206  540  557  460]\n",
      " [ 123  120  582 1121  674 2551  164   63]\n",
      " [ 949   74  951  881 1058  369  763  353]\n",
      " [ 418   12  644  359  599  338  367 2661]]\n",
      "Min_samples_leaf : 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.40      0.36      5398\n",
      "           5       0.42      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.59      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1369   22  931  538 1036  320  720  462]\n",
      " [  46 4574   45  115  376  156   77    9]\n",
      " [ 646   22 1956  850  289  691  632  312]\n",
      " [ 445  121  985 1465  670 1017  506  189]\n",
      " [ 592   55  292  707 2158  541  578  475]\n",
      " [ 115  118  620 1178  570 2545  166   86]\n",
      " [ 945   49  969  884 1044  391  757  359]\n",
      " [ 404   11  649  348  603  336  365 2682]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.47      0.45      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1353   27  923  522 1069  318  723  463]\n",
      " [  46 4576   45  115  374  154   79    9]\n",
      " [ 647   44 1965  844  274  691  616  317]\n",
      " [ 441   94 1005 1449  703 1013  504  189]\n",
      " [ 593   56  290  680 2210  537  545  487]\n",
      " [ 122  121  616 1176  576 2543  158   86]\n",
      " [ 935   58  983  861 1065  387  748  361]\n",
      " [ 409   10  653  350  606  336  349 2685]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.26      0.27      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.44      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1383   27  906  531 1083  329  702  437]\n",
      " [  46 4576   45  116  377  154   75    9]\n",
      " [ 674   48 1928  857  290  690  612  299]\n",
      " [ 459   90 1015 1441  714  995  495  189]\n",
      " [ 600   57  271  676 2234  541  541  478]\n",
      " [ 125  123  543 1163  561 2641  157   85]\n",
      " [ 963   50  964  887 1100  384  712  338]\n",
      " [ 446   12  654  347  597  326  355 2661]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.26      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.36      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1417   27  907  520 1043  335  701  448]\n",
      " [  46 4576   45  116  395  126   85    9]\n",
      " [ 677   48 1957  852  281  669  610  304]\n",
      " [ 485   90 1020 1429  673 1019  496  186]\n",
      " [ 615   57  265  656 2214  578  537  476]\n",
      " [ 135  123  540 1155  559 2646  157   83]\n",
      " [ 977   50  963  888 1070  388  713  349]\n",
      " [ 455   12  656  342  590  326  344 2673]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.36      0.34      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1394   23  903  536 1043  344  707  448]\n",
      " [  46 4576   45  116  395  126   85    9]\n",
      " [ 673   40 1970  874  273  670  594  304]\n",
      " [ 480   91  995 1438  675 1019  512  188]\n",
      " [ 602   68  261  650 2215  586  542  474]\n",
      " [ 113  118  532 1175  567 2647  159   87]\n",
      " [ 962   57  963  890 1077  379  721  349]\n",
      " [ 442   12  656  342  593  329  350 2674]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1392   23  911  535 1044  338  700  455]\n",
      " [  47 4576   45  116  395  126   84    9]\n",
      " [ 663   40 1971  873  284  671  592  304]\n",
      " [ 458   91  993 1435  717 1019  493  192]\n",
      " [ 602   68  259  649 2216  589  537  478]\n",
      " [ 110  119  530 1183  560 2646  159   91]\n",
      " [ 954   57  964  891 1082  379  713  358]\n",
      " [ 442   12  655  342  587  330  354 2676]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1386   31  930  531 1055  342  683  440]\n",
      " [  47 4576   45  116  403  126   76    9]\n",
      " [ 659   42 1981  867  306  671  590  282]\n",
      " [ 451   91 1000 1405  747 1019  486  199]\n",
      " [ 606   68  259  636 2272  591  531  435]\n",
      " [ 105  121  536 1137  607 2637  163   92]\n",
      " [ 942   68  977  878 1104  380  706  343]\n",
      " [ 442   15  663  340  600  331  363 2644]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.25      0.24      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.43      0.48      0.45      5398\n",
      "           6       0.20      0.13      0.15      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.40     43184\n",
      "weighted avg       0.41      0.41      0.40     43184\n",
      "\n",
      "[[1419   31  934  512 1051  344  664  443]\n",
      " [  69 4576   45  116  408  126   54    4]\n",
      " [ 675   41 1993  839  301  662  568  319]\n",
      " [ 455   91 1006 1347  772 1044  476  207]\n",
      " [ 635   68  280  607 2277  599  506  426]\n",
      " [ 108  152  536 1120  608 2609  156  109]\n",
      " [ 970   67  990  847 1107  394  680  343]\n",
      " [ 448   16  665  337  607  327  362 2636]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.91      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.25      0.24      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.43      0.48      0.45      5398\n",
      "           6       0.19      0.13      0.15      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1449   31  936  488 1039  337  680  438]\n",
      " [  69 4576   45  116  408  126   54    4]\n",
      " [ 687   41 1999  813  297  660  586  315]\n",
      " [ 460   90  997 1341  770 1044  520  176]\n",
      " [ 678   67  280  591 2274  564  510  434]\n",
      " [ 130  152  536 1108  613 2581  174  104]\n",
      " [1003   67  998  828 1100  378  692  332]\n",
      " [ 471   16  665  330  601  321  363 2631]]\n",
      "Min_samples_leaf : 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.25      0.24      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.43      0.48      0.45      5398\n",
      "           6       0.20      0.13      0.15      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1465   31  939  476 1030  337  678  442]\n",
      " [  69 4562   45  116  408  140   54    4]\n",
      " [ 707   40 2001  797  292  664  577  320]\n",
      " [ 461   80  993 1341  769 1053  499  202]\n",
      " [ 686   62  281  578 2268  568  519  436]\n",
      " [ 128  131  536 1105  612 2604  178  104]\n",
      " [1012   64 1006  821 1096  380  693  326]\n",
      " [ 474   15  671  331  600  323  354 2630]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.25      0.25      5398\n",
      "           4       0.32      0.41      0.36      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.60      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1447   31  957  471 1029  329  698  436]\n",
      " [  67 4562   46  116  408  140   55    4]\n",
      " [ 684   40 2006  788  300  696  594  290]\n",
      " [ 441   80 1002 1347  742 1064  529  193]\n",
      " [ 694   62  284  592 2217  576  537  436]\n",
      " [ 133  131  534 1123  592 2649  170   66]\n",
      " [1005   64 1014  815 1091  373  715  321]\n",
      " [ 466   15  683  326  597  330  363 2618]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.33      5398\n",
      "           3       0.24      0.24      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.19      0.13      0.16      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.41     43184\n",
      "weighted avg       0.41      0.40      0.41     43184\n",
      "\n",
      "[[1474   31  954  471  998  320  713  437]\n",
      " [  67 4562   47  115  413  140   50    4]\n",
      " [ 694   40 1993  778  300  697  605  291]\n",
      " [ 471   80 1006 1315  758 1046  523  199]\n",
      " [ 701   62  283  582 2155  573  606  436]\n",
      " [ 137  131  532 1127  572 2636  197   66]\n",
      " [1030   64 1014  796 1084  360  727  323]\n",
      " [ 475   15  683  330  595  313  363 2624]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.24      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.19      0.13      0.15      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1474   31  952  466 1008  332  704  431]\n",
      " [  67 4562   47  105  413  150   50    4]\n",
      " [ 701   40 1975  767  309  707  597  302]\n",
      " [ 469   80 1012 1322  760 1044  516  195]\n",
      " [ 702   62  284  572 2144  596  606  432]\n",
      " [ 140  131  516 1126  571 2654  194   66]\n",
      " [1033   64 1019  789 1098  365  706  324]\n",
      " [ 490   15  673  329  602  328  341 2620]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.25      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.19      0.13      0.16      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1484   31  968  463 1012  328  680  432]\n",
      " [  67 4562   56  105  413  150   41    4]\n",
      " [ 696   40 1997  778  300  689  596  302]\n",
      " [ 479   80 1037 1334  740 1021  511  196]\n",
      " [ 712   62  291  581 2139  593  588  432]\n",
      " [ 141  131  519 1129  591 2648  173   66]\n",
      " [1044   64 1020  791 1086  367  702  324]\n",
      " [ 495   15  672  329  601  324  341 2621]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.33      5398\n",
      "           3       0.24      0.25      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.49      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1484   31  968  431 1000  342  673  469]\n",
      " [  67 4562   49  112  411  150   43    4]\n",
      " [ 697   40 1988  779  285  700  588  321]\n",
      " [ 504   80 1019 1325  751 1005  479  235]\n",
      " [ 694   62  280  584 2136  598  596  448]\n",
      " [ 125  131  516 1119  608 2631  178   90]\n",
      " [1048   64 1004  778 1065  384  712  343]\n",
      " [ 476   15  675  318  615  329  328 2642]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.28      5398\n",
      "           1       0.92      0.85      0.88      5398\n",
      "           2       0.31      0.37      0.33      5398\n",
      "           3       0.24      0.24      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.50      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.40     43184\n",
      "weighted avg       0.41      0.41      0.40     43184\n",
      "\n",
      "[[1495   31  932  443 1001  343  679  474]\n",
      " [  67 4562   46  115  420  150   34    4]\n",
      " [ 701   40 1973  752  292  697  618  325]\n",
      " [ 504   80 1028 1307  744 1010  482  243]\n",
      " [ 717   62  286  576 2133  600  577  447]\n",
      " [ 116  131  516 1058  607 2677  197   96]\n",
      " [1054   64  987  783 1060  381  721  348]\n",
      " [ 487   15  662  333  615  336  313 2637]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.24      0.24      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.43      0.50      0.47      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1495   26  951  438  998  351  673  466]\n",
      " [  67 4526   46  115  444  161   35    4]\n",
      " [ 695   40 2002  744  290  697  602  328]\n",
      " [ 502   78 1043 1289  741 1011  492  242]\n",
      " [ 728   57  274  595 2117  604  592  431]\n",
      " [ 116  128  514 1072  569 2719  198   82]\n",
      " [1054   53  989  776 1057  389  734  346]\n",
      " [ 496   15  665  335  607  333  315 2632]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.37      0.34      5398\n",
      "           3       0.24      0.24      0.24      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.50      0.46      5398\n",
      "           6       0.20      0.14      0.17      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1465   26  963  441 1009  350  684  460]\n",
      " [  67 4526   46   83  457  180   35    4]\n",
      " [ 673   40 2024  737  290  697  614  323]\n",
      " [ 493   78 1016 1296  758 1004  510  243]\n",
      " [ 694   57  297  586 2158  589  587  430]\n",
      " [ 107  128  536 1053  591 2698  199   86]\n",
      " [1013   53  993  766 1089  387  751  346]\n",
      " [ 485   15  663  339  617  340  318 2621]]\n",
      "Min_samples_leaf : 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.42      0.50      0.46      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.40     43184\n",
      "weighted avg       0.41      0.40      0.40     43184\n",
      "\n",
      "[[1463   26  990  426 1012  356  673  452]\n",
      " [  67 4526   46   83  431  207   34    4]\n",
      " [ 676   40 2034  705  288  711  610  334]\n",
      " [ 484   78 1049 1218  764 1062  498  245]\n",
      " [ 686   57  292  587 2150  606  582  438]\n",
      " [ 105  128  547 1020  600 2714  198   86]\n",
      " [1013   53 1018  743 1087  399  738  347]\n",
      " [ 496   15  668  331  618  341  315 2614]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.39      0.34      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.42      0.50      0.46      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.40     43184\n",
      "weighted avg       0.41      0.41      0.40     43184\n",
      "\n",
      "[[1469   26 1001  414 1006  356  662  464]\n",
      " [  67 4526   46   81  433  209   32    4]\n",
      " [ 655   40 2093  697  288  708  582  335]\n",
      " [ 497   78 1086 1193  762 1060  477  245]\n",
      " [ 684   57  293  587 2128  609  583  457]\n",
      " [ 105  128  558 1010  599 2710  202   86]\n",
      " [1011   53 1025  738 1080  402  729  360]\n",
      " [ 502   15  674  328  600  337  290 2652]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.39      0.35      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.50      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1480   26  997  412 1039  340  639  465]\n",
      " [  67 4526   46   81  427  209   38    4]\n",
      " [ 655   40 2106  705  295  681  584  332]\n",
      " [ 497   78 1098 1203  781 1032  464  245]\n",
      " [ 673   50  275  591 2162  606  577  464]\n",
      " [ 102  128  554 1015  603 2704  206   86]\n",
      " [1020   53 1022  724 1109  386  715  369]\n",
      " [ 508   15  673  332  605  330  272 2663]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.39      0.35      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.50      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1446   26 1007  421 1043  348  647  460]\n",
      " [  67 4526   46   81  427  209   38    4]\n",
      " [ 641   40 2096  731  296  684  578  332]\n",
      " [ 487   78 1076 1224  778 1037  474  244]\n",
      " [ 662   50  273  590 2182  623  566  452]\n",
      " [  98  128  510 1038  603 2724  211   86]\n",
      " [1002   53 1013  746 1110  392  719  363]\n",
      " [ 498   15  678  331  608  333  276 2659]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.39      0.35      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1467   26 1012  413 1052  347  621  460]\n",
      " [  67 4526   46   81  427  209   38    4]\n",
      " [ 650   40 2128  696  302  698  552  332]\n",
      " [ 494   78 1109 1168  803 1072  430  244]\n",
      " [ 682   50  271  578 2193  613  559  452]\n",
      " [  99  128  522  917  603 2841  202   86]\n",
      " [1008   53 1031  736 1132  389  686  363]\n",
      " [ 493   15  684  342  621  332  252 2659]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.40      0.35      5398\n",
      "           3       0.24      0.21      0.22      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.53      0.48      5398\n",
      "           6       0.21      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1464   28 1015  408 1042  360  628  453]\n",
      " [  67 4526   49   78  427  209   38    4]\n",
      " [ 649   40 2148  677  299  698  555  332]\n",
      " [ 489   78 1128 1144  793 1080  445  241]\n",
      " [ 669   74  279  568 2186  633  555  434]\n",
      " [  98  128  534  904  592 2851  209   82]\n",
      " [1000   53 1039  721 1116  415  700  354]\n",
      " [ 493   22  694  323  621  336  253 2656]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.40      0.35      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1489   28 1014  408 1029  357  614  459]\n",
      " [  69 4526   49   76  427  209   38    4]\n",
      " [ 660   40 2134  717  288  672  550  337]\n",
      " [ 495   78 1105 1173  793 1078  433  243]\n",
      " [ 679   74  279  579 2204  625  513  445]\n",
      " [  98  128  538  901  607 2852  189   85]\n",
      " [1029   53 1038  722 1119  413  668  356]\n",
      " [ 507   22  696  324  614  338  239 2658]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.39      0.34      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.53      0.48      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1472   28 1004  410 1047  359  617  461]\n",
      " [  69 4526   49   71  426  215   38    4]\n",
      " [ 664   40 2094  719  289  674  585  333]\n",
      " [ 481   78 1097 1170  803 1086  434  249]\n",
      " [ 672   74  279  541 2229  638  513  452]\n",
      " [  91  128  518  899  617 2859  196   90]\n",
      " [1020   53 1022  714 1140  416  675  358]\n",
      " [ 501   22  684  329  620  341  242 2659]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1508   28 1008  414 1034  353  600  453]\n",
      " [  69 4526   51   69  427  214   38    4]\n",
      " [ 670   40 2073  740  282  686  577  330]\n",
      " [ 492   78 1082 1178  810 1087  429  242]\n",
      " [ 703   74  284  544 2251  611  496  435]\n",
      " [ 106  128  543  895  607 2846  188   85]\n",
      " [1066   53 1006  728 1140  390  669  346]\n",
      " [ 493   22  692  327  630  354  245 2635]]\n",
      "Min_samples_leaf : 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.21      0.23      5398\n",
      "           4       0.31      0.41      0.36      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1497   28 1007  402 1048  355  604  457]\n",
      " [  69 4526   51   69  409  214   39   21]\n",
      " [ 674   40 2076  731  284  692  571  330]\n",
      " [ 488   78 1104 1154  810 1086  436  242]\n",
      " [ 703   74  286  536 2239  593  517  450]\n",
      " [ 103  128  530  876  614 2872  190   85]\n",
      " [1066   53 1010  730 1121  392  674  352]\n",
      " [ 497   22  693  319  614  357  245 2651]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.21      0.23      5398\n",
      "           4       0.32      0.43      0.36      5398\n",
      "           5       0.43      0.53      0.48      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1516   28 1003  401 1072  364  565  449]\n",
      " [  69 4526   51   69  410  214   38   21]\n",
      " [ 689   40 2062  731  284  715  570  307]\n",
      " [ 489   78 1103 1154  818 1089  430  237]\n",
      " [ 703   74  291  531 2300  594  456  449]\n",
      " [ 104  128  526  876  615 2875  192   82]\n",
      " [1076   53 1008  727 1150  394  639  351]\n",
      " [ 489   22  693  319  639  368  235 2633]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1552   28  977  409 1065  361  561  445]\n",
      " [  71 4526   50   69  409  214   38   21]\n",
      " [ 697   40 2031  753  289  711  570  307]\n",
      " [ 530   78 1067 1172  808 1088  422  233]\n",
      " [ 715   74  288  540 2282  581  472  446]\n",
      " [ 104  128  520  886  615 2871  192   82]\n",
      " [1092   53  994  745 1132  391  644  347]\n",
      " [ 502   22  701  330  637  342  234 2630]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.31      0.38      0.34      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1544   28  998  411 1074  352  546  445]\n",
      " [  71 4526   47   72  409  214   38   21]\n",
      " [ 672   40 2062  763  292  711  550  308]\n",
      " [ 529   78 1059 1182  821 1081  410  238]\n",
      " [ 715   74  288  550 2291  567  467  446]\n",
      " [ 102  128  518  889  617 2874  188   82]\n",
      " [1079   53 1015  750 1132  386  636  347]\n",
      " [ 497   22  714  337  630  332  234 2632]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.32      0.43      0.36      5398\n",
      "           5       0.44      0.52      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1544   28  993  416 1080  346  549  442]\n",
      " [  71 4526   47   85  409  201   38   21]\n",
      " [ 673   40 1981  844  290  711  550  309]\n",
      " [ 529   78 1027 1234  824 1059  409  238]\n",
      " [ 714   74  281  560 2303  554  466  446]\n",
      " [ 102  128  513  946  621 2818  188   82]\n",
      " [1078   53 1002  763 1134  384  639  345]\n",
      " [ 497   22  699  352  636  326  234 2632]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.44      0.52      0.47      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.59      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1528   28 1010  415 1075  362  545  435]\n",
      " [  71 4526   47   85  410  201   38   20]\n",
      " [ 648   40 2022  802  290  748  544  304]\n",
      " [ 523   78 1041 1236  807 1061  411  241]\n",
      " [ 700   74  307  555 2286  556  480  440]\n",
      " [ 101  128  518  956  617 2815  189   74]\n",
      " [1067   53 1025  758 1128  397  640  330]\n",
      " [ 491   22  712  347  653  329  237 2607]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.44      0.53      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1500   28  980  427 1078  362  569  454]\n",
      " [  71 4526   47   66  410  220   38   20]\n",
      " [ 639   40 1997  804  297  755  553  313]\n",
      " [ 514   78 1029 1219  815 1081  417  245]\n",
      " [ 667   74  288  570 2289  555  512  443]\n",
      " [  97  128  519  897  621 2873  189   74]\n",
      " [1034   53 1003  767 1143  398  660  340]\n",
      " [ 467   22  696  355  640  332  257 2629]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.30      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.44      0.52      0.48      5398\n",
      "           6       0.21      0.12      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1560   28  990  426 1049  338  553  454]\n",
      " [  71 4526   47   59  410  227   38   20]\n",
      " [ 679   40 2011  802  279  734  550  303]\n",
      " [ 525   78 1045 1202  819 1070  421  238]\n",
      " [ 700   74  296  541 2304  542  502  439]\n",
      " [ 102  128  539  810  748 2811  189   71]\n",
      " [1038   53 1018  760 1134  376  666  353]\n",
      " [ 496   22  667  368  631  321  259 2634]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.30      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.44      0.52      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1570   28 1001  414 1050  339  542  454]\n",
      " [  71 4526   47   59  446  191   38   20]\n",
      " [ 680   40 2008  801  276  753  534  306]\n",
      " [ 533   78 1034 1176  808 1109  421  239]\n",
      " [ 723   74  297  523 2292  548  502  439]\n",
      " [ 110  128  571  771  738 2820  189   71]\n",
      " [1051   53 1023  756 1121  378  662  354]\n",
      " [ 499   22  667  357  630  332  258 2633]]\n",
      "Min_samples_leaf : 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29      5398\n",
      "           1       0.91      0.84      0.87      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.43      0.52      0.47      5398\n",
      "           6       0.21      0.12      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1565   28  977  428 1052  339  546  463]\n",
      " [  71 4526   47   58  446  192   38   20]\n",
      " [ 675   40 1972  828  286  753  536  308]\n",
      " [ 521   78 1023 1194  810 1099  428  245]\n",
      " [ 727   74  285  539 2284  546  501  442]\n",
      " [ 106  128  571  797  745 2794  186   71]\n",
      " [1050   53  993  771 1123  379  666  363]\n",
      " [ 506   22  662  369  625  329  263 2622]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.23      0.23      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.44      0.52      0.48      5398\n",
      "           6       0.21      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1542   24  977  450 1054  343  541  467]\n",
      " [  69 4526   43   64  446  192   38   20]\n",
      " [ 663   35 1931  874  276  758  547  314]\n",
      " [ 518   78 1013 1222  807 1098  431  231]\n",
      " [ 702   74  267  572 2298  547  495  443]\n",
      " [ 106   92  555  814  747 2829  186   69]\n",
      " [1035   52  985  806 1119  380  656  365]\n",
      " [ 493   20  658  380  634  331  259 2623]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(45,101):\n",
    "    dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f61ed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.31      0.39      0.35      5398\n",
      "           3       0.24      0.22      0.23      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.50      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1480   26  997  412 1039  340  639  465]\n",
      " [  67 4526   46   81  427  209   38    4]\n",
      " [ 655   40 2106  705  295  681  584  332]\n",
      " [ 497   78 1098 1203  781 1032  464  245]\n",
      " [ 673   50  275  591 2162  606  577  464]\n",
      " [ 102  128  554 1015  603 2704  206   86]\n",
      " [1020   53 1022  724 1109  386  715  369]\n",
      " [ 508   15  673  332  605  330  272 2663]]\n"
     ]
    }
   ],
   "source": [
    "#Min samples leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "#Min_samples_leaf= 83 gives best f1-score\n",
    "dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=83,random_state=1)\n",
    "dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f74fe12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruning Technique Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c62a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.38      0.31      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.28      0.26      0.27      5398\n",
      "           3       0.24      0.25      0.25      5398\n",
      "           4       0.32      0.30      0.31      5398\n",
      "           5       0.46      0.32      0.38      5398\n",
      "           6       0.20      0.21      0.20      5398\n",
      "           7       0.46      0.50      0.48      5398\n",
      "\n",
      "    accuracy                           0.38     43184\n",
      "   macro avg       0.40      0.38      0.39     43184\n",
      "weighted avg       0.40      0.38      0.39     43184\n",
      "\n",
      "[[2035    9  619  316  702  131  934  652]\n",
      " [ 130 4405   27  425  180  121   90   20]\n",
      " [1120   28 1410  763  308  366  893  510]\n",
      " [ 644   57  788 1335  617  769  757  431]\n",
      " [1050   17  339  561 1640  274  902  615]\n",
      " [ 556   73  584 1084  525 1718  499  359]\n",
      " [1315   17  766  677  739  202 1129  553]\n",
      " [ 768    8  477  300  447  172  511 2715]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Entropy \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc2=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxdepth with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc9907ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5398\n",
      "           1       0.73      0.91      0.81      5398\n",
      "           2       0.00      0.00      0.00      5398\n",
      "           3       0.00      0.00      0.00      5398\n",
      "           4       0.00      0.00      0.00      5398\n",
      "           5       0.00      0.00      0.00      5398\n",
      "           6       0.00      0.00      0.00      5398\n",
      "           7       0.15      0.98      0.25      5398\n",
      "\n",
      "    accuracy                           0.24     43184\n",
      "   macro avg       0.11      0.24      0.13     43184\n",
      "weighted avg       0.11      0.24      0.13     43184\n",
      "\n",
      "[[   0  439    0    0    0    0    0 4959]\n",
      " [   0 4890    0    0    0    0    0  508]\n",
      " [   0  277    0    0    0    0    0 5121]\n",
      " [   0  254    0    0    0    0    0 5144]\n",
      " [   0  269    0    0    0    0    0 5129]\n",
      " [   0  143    0    0    0    0    0 5255]\n",
      " [   0  312    0    0    0    0    0 5086]\n",
      " [   0  101    0    0    0    0    0 5297]]\n",
      "Max depth : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.07      0.11      5398\n",
      "           1       0.97      0.88      0.93      5398\n",
      "           2       0.25      0.65      0.36      5398\n",
      "           3       0.00      0.00      0.00      5398\n",
      "           4       0.21      0.90      0.35      5398\n",
      "           5       0.00      0.00      0.00      5398\n",
      "           6       0.00      0.00      0.00      5398\n",
      "           7       0.00      0.00      0.00      5398\n",
      "\n",
      "    accuracy                           0.31     43184\n",
      "   macro avg       0.21      0.31      0.22     43184\n",
      "weighted avg       0.21      0.31      0.22     43184\n",
      "\n",
      "[[ 381   58 1432    0 3527    0    0    0]\n",
      " [ 123 4767   69    0  439    0    0    0]\n",
      " [ 259   18 3495    0 1626    0    0    0]\n",
      " [ 243   11 2378    0 2766    0    0    0]\n",
      " [ 261    8  289    0 4840    0    0    0]\n",
      " [ 141    2 2524    0 2731    0    0    0]\n",
      " [ 282   30 1839    0 3247    0    0    0]\n",
      " [  88   13 1839    0 3458    0    0    0]]\n",
      "Max depth : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.43      0.31      5398\n",
      "           1       0.99      0.84      0.91      5398\n",
      "           2       0.26      0.59      0.36      5398\n",
      "           3       0.00      0.00      0.00      5398\n",
      "           4       0.26      0.67      0.37      5398\n",
      "           5       0.49      0.23      0.31      5398\n",
      "           6       0.05      0.00      0.01      5398\n",
      "           7       0.00      0.00      0.00      5398\n",
      "\n",
      "    accuracy                           0.35     43184\n",
      "   macro avg       0.29      0.35      0.28     43184\n",
      "weighted avg       0.29      0.35      0.28     43184\n",
      "\n",
      "[[2347   19 1381    0 1415  197   39    0]\n",
      " [  40 4513   47    0  522   22  254    0]\n",
      " [1237    2 3178    0  449  516   16    0]\n",
      " [ 967    1 2398    0 1867  155   10    0]\n",
      " [1458    0  300    0 3616   16    8    0]\n",
      " [ 395    1 1318    0 2446 1237    1    0]\n",
      " [1580   12 1835    0 1862   91   18    0]\n",
      " [1731    3 1639    0 1749  266   10    0]]\n",
      "Max depth : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.44      0.31      5398\n",
      "           1       1.00      0.84      0.91      5398\n",
      "           2       0.26      0.55      0.36      5398\n",
      "           3       0.26      0.02      0.04      5398\n",
      "           4       0.27      0.60      0.37      5398\n",
      "           5       0.40      0.40      0.40      5398\n",
      "           6       0.24      0.00      0.01      5398\n",
      "           7       0.00      0.00      0.00      5398\n",
      "\n",
      "    accuracy                           0.36     43184\n",
      "   macro avg       0.33      0.36      0.30     43184\n",
      "weighted avg       0.33      0.36      0.30     43184\n",
      "\n",
      "[[2349   11 1235   81 1256  437   29    0]\n",
      " [ 138 4513   47    0  629   71    0    0]\n",
      " [1220    0 2979  123  366  694   16    0]\n",
      " [ 917    1 2223  115 1417  715   10    0]\n",
      " [1401    0  273   20 3232  471    1    0]\n",
      " [ 271    1 1287   19 1661 2158    1    0]\n",
      " [1617    1 1748   58 1703  250   21    0]\n",
      " [1624    0 1573   33 1620  538   10    0]]\n",
      "Max depth : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27      5398\n",
      "           1       0.88      0.84      0.86      5398\n",
      "           2       0.26      0.53      0.35      5398\n",
      "           3       0.25      0.02      0.04      5398\n",
      "           4       0.27      0.62      0.37      5398\n",
      "           5       0.46      0.39      0.42      5398\n",
      "           6       0.12      0.00      0.01      5398\n",
      "           7       0.29      0.20      0.23      5398\n",
      "\n",
      "    accuracy                           0.36     43184\n",
      "   macro avg       0.35      0.36      0.32     43184\n",
      "weighted avg       0.35      0.36      0.32     43184\n",
      "\n",
      "[[1535   54 1264   82 1384  244   45  790]\n",
      " [  49 4513   47    0  629   71   60   29]\n",
      " [ 821  192 2879  116  394  590   17  389]\n",
      " [ 598  138 2156  105 1460  612   23  306]\n",
      " [ 954    4  276   22 3336  359    8  439]\n",
      " [ 167   85 1215   19 1726 2081   11   94]\n",
      " [1069   83 1699   58 1755  171   24  539]\n",
      " [ 573   31 1586   24 1710  415    6 1053]]\n",
      "Max depth : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.42      0.32      5398\n",
      "           1       0.92      0.82      0.86      5398\n",
      "           2       0.28      0.52      0.36      5398\n",
      "           3       0.27      0.03      0.06      5398\n",
      "           4       0.30      0.49      0.37      5398\n",
      "           5       0.48      0.49      0.48      5398\n",
      "           6       0.14      0.01      0.01      5398\n",
      "           7       0.46      0.39      0.42      5398\n",
      "\n",
      "    accuracy                           0.39     43184\n",
      "   macro avg       0.39      0.39      0.36     43184\n",
      "weighted avg       0.39      0.39      0.36     43184\n",
      "\n",
      "[[2256   36 1214   39 1081  258   42  472]\n",
      " [ 179 4412   37  250  226  100   60  134]\n",
      " [1128  115 2782   78  302  676   21  296]\n",
      " [ 895  100 1989  186 1052  848   15  313]\n",
      " [1362    2  201   23 2641  393    9  767]\n",
      " [ 300   68  946   36 1297 2638   10  103]\n",
      " [1534   75 1621   48 1438  211   27  444]\n",
      " [ 934    1 1122   35  760  426    7 2113]]\n",
      "Max depth : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.42      0.33      5398\n",
      "           1       0.94      0.82      0.88      5398\n",
      "           2       0.29      0.49      0.37      5398\n",
      "           3       0.26      0.09      0.13      5398\n",
      "           4       0.29      0.50      0.37      5398\n",
      "           5       0.46      0.59      0.52      5398\n",
      "           6       0.15      0.00      0.01      5398\n",
      "           7       0.60      0.35      0.44      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.38     43184\n",
      "weighted avg       0.41      0.41      0.38     43184\n",
      "\n",
      "[[2254   22 1253   69 1188  330   31  251]\n",
      " [ 137 4412    0  339  376   94    0   40]\n",
      " [1068   65 2647  282  321  861   17  137]\n",
      " [ 827   70 1684  481 1107 1083   22  124]\n",
      " [1287    0  168  140 2703  590   10  500]\n",
      " [ 205   52  542  303 1102 3179    0   15]\n",
      " [1522   56 1592  155 1557  307   16  193]\n",
      " [ 916    1 1167   80  878  472    8 1876]]\n",
      "Max depth : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.34      5398\n",
      "           1       0.93      0.82      0.87      5398\n",
      "           2       0.30      0.50      0.37      5398\n",
      "           3       0.20      0.13      0.16      5398\n",
      "           4       0.32      0.46      0.37      5398\n",
      "           5       0.46      0.53      0.49      5398\n",
      "           6       0.17      0.01      0.03      5398\n",
      "           7       0.60      0.35      0.45      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.41      0.40      0.38     43184\n",
      "weighted avg       0.41      0.40      0.38     43184\n",
      "\n",
      "[[2290   17 1207  260  980  331   79  234]\n",
      " [ 147 4412   18  333  300  121   19   48]\n",
      " [1044   67 2689  541  130  681   95  151]\n",
      " [ 799   96 1652  716  943 1014   57  121]\n",
      " [1299    2  167  427 2473  524   30  476]\n",
      " [ 213   79  552  757  870 2836   22   69]\n",
      " [1509   57 1582  367 1348  270   74  191]\n",
      " [ 939    2 1119  214  772  378   60 1914]]\n"
     ]
    }
   ],
   "source": [
    "#apply max_depth pruning technique on DecisionTreeClassifier with Entropy\n",
    "for i in range(1,9):\n",
    "    dtc2_max_depth=DecisionTreeClassifier(max_depth=i,random_state=1,criterion='entropy')\n",
    "    print('Max depth :',i)\n",
    "    dtc2_max_depth=create_model(dtc2_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0969532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min_sample_leaf with entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce07f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.45      0.46      0.45      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1486   11  928  533  965  260  796  419]\n",
      " [  39 4550   34  137  461  163   12    2]\n",
      " [ 587   32 1946  963  326  616  595  333]\n",
      " [ 450  128 1112 1511  674  937  401  185]\n",
      " [ 641   38  287  797 2150  454  614  417]\n",
      " [ 166  126  574 1030  741 2489  216   56]\n",
      " [ 938   28  976  846 1138  369  773  330]\n",
      " [ 481   11  675  428  578  264  314 2647]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.36      0.32      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.40      0.34      5398\n",
      "           5       0.45      0.48      0.46      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.61      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1498   11  910  537  966  270  782  424]\n",
      " [  39 4550   41  123  473  170    0    2]\n",
      " [ 619   32 1921  922  331  641  610  322]\n",
      " [ 457  128 1116 1455  657  986  420  179]\n",
      " [ 635   38  292  813 2143  480  587  410]\n",
      " [ 171  126  557  941  737 2589  214   63]\n",
      " [ 956   28  942  845 1146  367  782  332]\n",
      " [ 486   11  666  422  573  273  312 2655]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.30      0.39      0.34      5398\n",
      "           5       0.45      0.48      0.46      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.60      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1499   14  887  559  969  265  776  429]\n",
      " [  39 4550   41  142  454  170    0    2]\n",
      " [ 633   33 1872  914  342  639  625  340]\n",
      " [ 469  128 1106 1489  619  976  429  182]\n",
      " [ 642   53  289  847 2098  482  575  412]\n",
      " [ 158  122  554  968  734 2573  222   67]\n",
      " [ 986   38  908  875 1110  377  773  331]\n",
      " [ 476    8  647  412  582  284  313 2676]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.30      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.31      0.39      0.34      5398\n",
      "           5       0.45      0.48      0.46      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1529   14  875  557  961  263  771  428]\n",
      " [  39 4550   41  142  443  169   12    2]\n",
      " [ 626   32 1894  927  340  633  615  331]\n",
      " [ 473  128 1097 1479  602  974  454  191]\n",
      " [ 657   53  288  823 2099  474  588  416]\n",
      " [ 160  121  561  931  707 2567  283   68]\n",
      " [1007   38  892  878 1096  377  789  321]\n",
      " [ 475    8  648  401  591  278  326 2671]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.44      0.48      0.46      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1519   14  881  555  979  263  768  419]\n",
      " [  51 4550   16  142  443  194    0    2]\n",
      " [ 563   32 1910  954  342  653  605  339]\n",
      " [ 507  117 1069 1477  590 1004  443  191]\n",
      " [ 667   48  277  780 2104  477  630  415]\n",
      " [ 172  102  551 1012  618 2600  265   78]\n",
      " [1002   35  901  893 1061  384  801  321]\n",
      " [ 478    8  631  411  595  300  324 2651]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.29      0.30      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.45      0.48      0.47      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1542   14  892  539  992  264  726  429]\n",
      " [  51 4550   16  142  463  174    0    2]\n",
      " [ 590   32 1893  956  339  624  616  348]\n",
      " [ 493  119 1103 1472  626  979  419  187]\n",
      " [ 660   67  278  756 2132  479  603  423]\n",
      " [ 169  102  553  977  632 2618  255   92]\n",
      " [1044   35  901  868 1090  372  764  324]\n",
      " [ 504   11  628  400  590  296  308 2661]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.44      0.49      0.46      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1489   13  897  521 1018  271  755  434]\n",
      " [  51 4535   17  157  463  173    0    2]\n",
      " [ 547   31 1884  943  368  670  618  337]\n",
      " [ 489  117 1086 1466  648  999  410  183]\n",
      " [ 657   52  278  735 2149  493  610  424]\n",
      " [ 166  120  543  998  633 2631  220   87]\n",
      " [ 970   35  901  858 1121  381  795  337]\n",
      " [ 502    8  620  400  585  307  320 2656]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.25      0.27      0.26      5398\n",
      "           4       0.30      0.40      0.34      5398\n",
      "           5       0.44      0.50      0.47      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.61      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1499   14  878  515 1013  283  776  420]\n",
      " [  51 4544   17  132  466  181    0    7]\n",
      " [ 561   31 1829  924  353  683  695  322]\n",
      " [ 488  116 1038 1473  652 1005  458  168]\n",
      " [ 654   66  280  691 2135  491  653  428]\n",
      " [ 167   90  554  917  700 2676  231   63]\n",
      " [ 979   35  911  849 1113  375  813  323]\n",
      " [ 510   11  618  372  572  322  331 2662]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.25      0.27      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.45      0.50      0.47      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.60      0.50      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1482   14  907  506 1012  289  769  419]\n",
      " [  50 4543   18  130  468  182    0    7]\n",
      " [ 547   31 1851  930  349  679  685  326]\n",
      " [ 467  117 1053 1474  656 1004  443  184]\n",
      " [ 661   65  278  688 2151  487  642  426]\n",
      " [ 168   90  566  964  646 2681  220   63]\n",
      " [ 966   36  914  847 1115  371  810  339]\n",
      " [ 513   12  603  371  570  321  334 2674]]\n",
      "Min_samples_leaf : 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.29      0.30      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.25      0.28      0.26      5398\n",
      "           4       0.32      0.40      0.35      5398\n",
      "           5       0.44      0.51      0.47      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.61      0.49      0.55      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1554   14  903  522  966  316  707  416]\n",
      " [  82 4529   18  129  442  182    9    7]\n",
      " [ 585   30 1830  933  346  703  646  325]\n",
      " [ 486   93 1050 1509  639 1023  442  156]\n",
      " [ 690   33  269  746 2138  511  597  414]\n",
      " [ 171   90  547  966  586 2750  231   57]\n",
      " [ 991   35  913  886 1072  394  777  330]\n",
      " [ 520    8  610  378  592  325  295 2670]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.29      0.34      0.31      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.39      0.34      5398\n",
      "           5       0.44      0.51      0.47      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.61      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1530   18  921  550  999  309  680  391]\n",
      " [  82 4527   18  129  417  200    9   16]\n",
      " [ 617   33 1813  987  329  718  574  327]\n",
      " [ 483   93 1024 1522  643 1071  407  155]\n",
      " [ 690   46  269  752 2089  508  614  430]\n",
      " [ 154   68  592  994  556 2744  214   76]\n",
      " [ 961   34  912  918 1109  400  754  310]\n",
      " [ 535   11  616  388  597  323  289 2639]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.44      0.52      0.48      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1508   18  919  553 1003  308  688  401]\n",
      " [  82 4527   18  129  433  184    9   16]\n",
      " [ 580   33 1829  984  329  722  580  341]\n",
      " [ 485   94 1025 1499  645 1082  403  165]\n",
      " [ 688   45  259  740 2122  495  620  429]\n",
      " [ 153   69  592  950  548 2794  216   76]\n",
      " [ 954   34  897  935 1102  397  764  315]\n",
      " [ 531   11  614  385  600  325  287 2645]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.44      0.51      0.47      5398\n",
      "           6       0.21      0.14      0.17      5398\n",
      "           7       0.61      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1479   18  942  555 1012  312  688  392]\n",
      " [  82 4527   21  126  398  219    9   16]\n",
      " [ 571   33 1831  983  322  722  602  334]\n",
      " [ 481   95 1002 1538  648 1066  413  155]\n",
      " [ 679   45  274  752 2129  505  591  423]\n",
      " [ 153   69  579  978  575 2769  199   76]\n",
      " [ 942   34  910  952 1104  399  750  307]\n",
      " [ 528   11  605  397  615  327  282 2633]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.29      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.44      0.51      0.47      5398\n",
      "           6       0.20      0.14      0.16      5398\n",
      "           7       0.61      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1449   18  937  560 1030  313  703  388]\n",
      " [  82 4518   21  126  433  193    9   16]\n",
      " [ 561   33 1853  990  349  709  596  307]\n",
      " [ 456   94 1006 1545  636 1064  429  168]\n",
      " [ 663   41  263  750 2140  503  629  409]\n",
      " [ 142   59  576  982  612 2745  208   74]\n",
      " [ 938   34  900  974 1134  393  732  293]\n",
      " [ 518   11  612  404  623  330  293 2607]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29      5398\n",
      "           1       0.93      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.39      0.35      5398\n",
      "           5       0.44      0.51      0.47      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.60      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1471   23  950  552 1011  318  681  392]\n",
      " [  82 4518   21  126  433  193    9   16]\n",
      " [ 574   39 1867  994  334  709  574  307]\n",
      " [ 440  100 1024 1533  618 1078  407  198]\n",
      " [ 668   41  277  750 2116  521  599  426]\n",
      " [ 129   59  563  941  600 2769  252   85]\n",
      " [ 938   53  911  977 1111  403  693  312]\n",
      " [ 523   11  626  401  612  338  282 2605]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.51      0.47      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1472   23  945  552 1019  318  681  388]\n",
      " [  82 4518   21  126  432  194    9   16]\n",
      " [ 577   30 1855  978  334  731  575  318]\n",
      " [ 443   85 1004 1520  633 1093  405  215]\n",
      " [ 665   39  267  762 2151  525  576  413]\n",
      " [ 130   51  562  942  601 2777  250   85]\n",
      " [ 949   51  900  959 1119  408  700  312]\n",
      " [ 523   10  587  390  633  339  279 2637]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.43      0.51      0.47      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1446   23  958  542 1015  318  702  394]\n",
      " [  82 4518   21  126  431  194    9   17]\n",
      " [ 576   30 1869  961  324  723  584  331]\n",
      " [ 428   85 1016 1502  658 1095  396  218]\n",
      " [ 645   39  269  760 2161  533  585  406]\n",
      " [ 128   51  566  930  617 2764  239  103]\n",
      " [ 909   51  907  950 1140  411  714  316]\n",
      " [ 515   10  593  382  633  339  284 2642]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.31      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.44      0.50      0.47      5398\n",
      "           6       0.20      0.13      0.15      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1471   23  914  537 1038  319  701  395]\n",
      " [  82 4518   21  126  432  193    9   17]\n",
      " [ 588   30 1849  965  346  717  580  323]\n",
      " [ 430   93 1009 1510  668 1058  413  217]\n",
      " [ 638   39  239  753 2210  515  583  421]\n",
      " [ 125   55  556  945  686 2721  204  106]\n",
      " [ 943   51  890  957 1174  391  686  306]\n",
      " [ 513   10  580  401  643  332  285 2634]]\n",
      "Min_samples_leaf : 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.51      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1468   23  949  520 1019  327  697  395]\n",
      " [  82 4518   11  136  432  193    9   17]\n",
      " [ 581   30 1858  987  340  708  566  328]\n",
      " [ 395   93 1049 1508  662 1071  399  221]\n",
      " [ 654   37  247  736 2195  539  569  421]\n",
      " [ 114   55  570  951  687 2734  193   94]\n",
      " [ 918   51  908  961 1161  412  673  314]\n",
      " [ 504   10  592  391  642  339  287 2633]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.42      0.50      0.46      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1472   19  907  537 1040  337  692  394]\n",
      " [  70 4518   11  136  444  193    9   17]\n",
      " [ 578   22 1837 1028  341  733  537  322]\n",
      " [ 390   93  993 1534  665 1106  395  222]\n",
      " [ 635   37  229  756 2200  545  575  421]\n",
      " [ 100   55  555  964  694 2720  197  113]\n",
      " [ 900   51  880  969 1175  420  689  314]\n",
      " [ 517    9  579  388  646  348  285 2626]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.25      0.29      0.26      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.50      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1459   19  934  542 1032  328  684  400]\n",
      " [  70 4518   11  136  444  193    9   17]\n",
      " [ 591   22 1843 1035  343  701  539  324]\n",
      " [ 406   94  981 1557  670 1068  391  231]\n",
      " [ 644   37  230  764 2212  532  557  422]\n",
      " [  99   57  588  929  709 2724  198   94]\n",
      " [ 905   51  889  980 1191  400  666  316]\n",
      " [ 513    9  587  411  645  338  266 2629]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.34      0.32      5398\n",
      "           3       0.25      0.28      0.26      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.52      0.47      5398\n",
      "           6       0.20      0.13      0.16      5398\n",
      "           7       0.60      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1449   19  933  546 1024  349  685  393]\n",
      " [  70 4518   11  136  444  193    9   17]\n",
      " [ 557   22 1841 1017  343  751  543  324]\n",
      " [ 391   95  969 1533  672 1124  389  225]\n",
      " [ 651   38  227  738 2236  559  545  404]\n",
      " [  99   57  573  907  681 2801  186   94]\n",
      " [ 884   52  890  964 1185  436  675  312]\n",
      " [ 508    9  591  400  650  360  269 2611]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.42      0.51      0.46      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.60      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1418   23  939  548 1034  363  681  392]\n",
      " [  59 4518   11  136  460  177   20   17]\n",
      " [ 540   22 1871  995  341  765  537  327]\n",
      " [ 418   95  983 1493  727 1136  341  205]\n",
      " [ 643   30  218  725 2305  558  526  393]\n",
      " [  88   58  576  911  719 2768  184   94]\n",
      " [ 871   53  900  961 1193  443  658  319]\n",
      " [ 508    7  599  391  659  366  263 2605]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.34      0.32      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.43      0.52      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.60      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1439   23  929  527 1037  356  696  391]\n",
      " [  59 4518    7  140  444  193   20   17]\n",
      " [ 579   22 1852  993  348  733  552  319]\n",
      " [ 438   95  964 1413  715 1160  400  213]\n",
      " [ 660   30  213  711 2320  555  532  377]\n",
      " [  88   60  561  908  700 2799  187   95]\n",
      " [ 889   54  895  937 1201  430  672  320]\n",
      " [ 514    7  597  374  683  349  278 2596]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.28      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1420   25  957  523 1046  355  674  398]\n",
      " [  59 4518    7  130  442  193   32   17]\n",
      " [ 560   24 1912  983  338  747  514  320]\n",
      " [ 434   95  973 1405  710 1161  396  224]\n",
      " [ 641   12  216  695 2320  585  537  392]\n",
      " [  88   60  569  909  684 2809  184   95]\n",
      " [ 882   64  907  912 1207  439  659  328]\n",
      " [ 498    7  600  364  682  354  272 2621]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.28      5398\n",
      "           1       0.94      0.84      0.89      5398\n",
      "           2       0.31      0.35      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.58      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.41     43184\n",
      "weighted avg       0.41      0.41      0.41     43184\n",
      "\n",
      "[[1398   25  959  522 1047  361  667  419]\n",
      " [  59 4518    7  130  442  193   32   17]\n",
      " [ 565   24 1883  982  338  762  515  329]\n",
      " [ 375   96  977 1400  729 1160  387  274]\n",
      " [ 633   13  221  712 2304  584  526  405]\n",
      " [  81   61  553  920  671 2831  184   97]\n",
      " [ 860   64  920  906 1216  440  652  340]\n",
      " [ 480    8  604  359  677  355  269 2646]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.29      5398\n",
      "           1       0.94      0.84      0.88      5398\n",
      "           2       0.31      0.36      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.31      0.43      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1410   25  965  512 1044  358  666  418]\n",
      " [  59 4518    7  141  442  182   32   17]\n",
      " [ 569   24 1929  969  337  749  494  327]\n",
      " [ 380   97  992 1414  712 1147  384  272]\n",
      " [ 639   13  233  706 2297  587  522  401]\n",
      " [  81   64  553  968  672 2796  181   83]\n",
      " [ 863   64  940  909 1196  440  647  339]\n",
      " [ 484    8  607  357  669  360  271 2642]]\n",
      "Min_samples_leaf : 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.31      0.36      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.42      0.52      0.46      5398\n",
      "           6       0.20      0.12      0.15      5398\n",
      "           7       0.59      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1479   25  964  507 1023  357  638  405]\n",
      " [  70 4518    7  141  442  182   21   17]\n",
      " [ 612   23 1933  983  321  733  470  323]\n",
      " [ 397   63 1020 1408  699 1170  371  270]\n",
      " [ 705    9  233  690 2278  583  514  386]\n",
      " [  78   52  580  988  672 2784  164   80]\n",
      " [ 908   58  949  895 1182  441  627  338]\n",
      " [ 515    6  609  348  647  361  273 2639]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.31      0.36      0.33      5398\n",
      "           3       0.23      0.26      0.25      5398\n",
      "           4       0.32      0.43      0.36      5398\n",
      "           5       0.42      0.51      0.46      5398\n",
      "           6       0.21      0.11      0.15      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1512   25  965  511 1015  355  607  408]\n",
      " [  70 4518    7  150  442  173   21   17]\n",
      " [ 628   23 1928  991  307  725  474  322]\n",
      " [ 401   65 1053 1422  690 1150  345  272]\n",
      " [ 722    9  233  720 2303  576  448  387]\n",
      " [  87   52  538 1052  671 2755  163   80]\n",
      " [ 933   58  943  914 1168  434  606  342]\n",
      " [ 535    6  612  358  640  358  258 2631]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.35      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.42      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.60      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1501   25  976  542  992  381  585  396]\n",
      " [  70 4519    7  149  442  173   21   17]\n",
      " [ 593   23 1908 1037  307  767  456  307]\n",
      " [ 406   65 1080 1472  681 1167  289  238]\n",
      " [ 713    9  251  737 2293  578  430  387]\n",
      " [  88   52  507 1041  657 2819  164   70]\n",
      " [ 924   58  962  910 1151  475  585  333]\n",
      " [ 555    6  614  363  645  361  240 2614]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.23      0.28      0.25      5398\n",
      "           4       0.31      0.41      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.61      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1506   25  974  565 1003  368  581  376]\n",
      " [  70 4519    7  149  442  173   21   17]\n",
      " [ 595   23 1888 1054  312  762  450  314]\n",
      " [ 394   65 1069 1508  703 1154  296  209]\n",
      " [ 743    9  251  803 2239  576  414  363]\n",
      " [ 103   51  503 1050  671 2802  154   64]\n",
      " [ 932   58  953  961 1155  456  577  306]\n",
      " [ 545    6  613  382  662  360  240 2590]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.22      0.26      0.24      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.11      0.14      5398\n",
      "           7       0.61      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1503   25  954  567  997  363  612  377]\n",
      " [  70 4519    7  149  439  173   21   20]\n",
      " [ 572   23 1850 1063  309  786  481  314]\n",
      " [ 372   65 1057 1423  708 1222  343  208]\n",
      " [ 708    9  250  801 2249  575  432  374]\n",
      " [  85   51  503 1025  651 2827  169   87]\n",
      " [ 928   58  945  959 1165  443  594  306]\n",
      " [ 524    6  605  381  667  367  255 2593]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.35      0.33      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.42      0.53      0.47      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.60      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1488   25  964  572 1009  358  600  382]\n",
      " [  70 4519    7  130  467  173   12   20]\n",
      " [ 567   23 1896 1012  315  786  477  322]\n",
      " [ 372   66 1032 1455  718 1217  329  209]\n",
      " [ 704    9  252  816 2250  567  426  374]\n",
      " [  84   51  513  986  655 2848  174   87]\n",
      " [ 915   58  963  953 1186  430  584  309]\n",
      " [ 515    6  624  379  672  364  237 2601]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.31      0.42      0.36      5398\n",
      "           5       0.43      0.53      0.47      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.60      0.48      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1496   25  954  564 1021  356  596  386]\n",
      " [  70 4519    7  131  467  172   12   20]\n",
      " [ 574   23 1886 1006  319  792  481  317]\n",
      " [ 369   66 1051 1443  728 1216  317  208]\n",
      " [ 704    9  259  800 2283  552  411  380]\n",
      " [  90   51  516  953  677 2877  146   88]\n",
      " [ 930   58  960  944 1197  429  570  310]\n",
      " [ 511    6  627  375  681  363  239 2596]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.27      0.29      5398\n",
      "           1       0.96      0.84      0.90      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.54      0.47      5398\n",
      "           6       0.20      0.11      0.14      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1467   25 1002  554 1005  362  588  395]\n",
      " [  70 4518    7  134  467  170   12   20]\n",
      " [ 536   13 1936 1013  280  785  491  344]\n",
      " [ 349   35 1076 1483  708 1197  339  211]\n",
      " [ 703    7  279  804 2204  578  412  411]\n",
      " [  90   34  531  972  648 2889  146   88]\n",
      " [ 907   55  995  949 1149  451  573  319]\n",
      " [ 501    5  637  376  654  364  241 2620]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.27      0.29      5398\n",
      "           1       0.96      0.84      0.90      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.28      0.25      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.53      0.47      5398\n",
      "           6       0.20      0.11      0.14      5398\n",
      "           7       0.59      0.49      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1451   25 1005  560 1004  361  591  401]\n",
      " [  70 4518    7  134  467  170   12   20]\n",
      " [ 524   13 1930 1019  281  784  491  356]\n",
      " [ 374   35 1025 1494  705 1195  359  211]\n",
      " [ 685    7  283  801 2206  582  415  419]\n",
      " [  84   34  541  973  653 2878  147   88]\n",
      " [ 896   55  986  970 1145  447  572  327]\n",
      " [ 497    5  648  386  651  346  239 2626]]\n",
      "Min_samples_leaf : 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.43      0.53      0.47      5398\n",
      "           6       0.20      0.10      0.14      5398\n",
      "           7       0.59      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1472   25 1008  556 1022  362  558  395]\n",
      " [  70 4532    7  136  465  154   12   22]\n",
      " [ 535   14 1970  973  281  790  480  355]\n",
      " [ 382   49 1046 1453  712 1182  353  221]\n",
      " [ 727   14  287  793 2196  573  387  421]\n",
      " [  84   57  542  969  668 2857  133   88]\n",
      " [ 923   58  981  970 1143  446  552  325]\n",
      " [ 508    6  656  377  667  346  234 2604]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.27      0.29      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.23      0.27      0.25      5398\n",
      "           4       0.31      0.41      0.35      5398\n",
      "           5       0.42      0.53      0.47      5398\n",
      "           6       0.20      0.10      0.14      5398\n",
      "           7       0.59      0.48      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1467   25 1015  554 1023  362  558  394]\n",
      " [  70 4532    7  136  465  154   12   22]\n",
      " [ 545   14 1966  979  281  790  476  347]\n",
      " [ 377   49 1049 1449  712 1185  352  225]\n",
      " [ 691   14  284  795 2193  612  387  422]\n",
      " [  84   57  545  970  679 2846  129   88]\n",
      " [ 902   58  992  972 1140  464  549  321]\n",
      " [ 509    6  648  379  666  359  234 2597]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.37      0.33      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.52      0.47      5398\n",
      "           6       0.20      0.09      0.13      5398\n",
      "           7       0.60      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1499   25 1017  541 1068  358  510  380]\n",
      " [  70 4532    7  136  465  154   12   22]\n",
      " [ 548   14 1986  979  293  782  452  344]\n",
      " [ 371   49 1074 1433  767 1150  342  212]\n",
      " [ 693   14  291  681 2440  534  346  399]\n",
      " [  83   57  597  923  703 2807  130   98]\n",
      " [ 926   58 1022  959 1242  421  500  270]\n",
      " [ 520    6  683  366  708  340  221 2554]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.30      0.36      0.33      5398\n",
      "           3       0.24      0.26      0.25      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.53      0.47      5398\n",
      "           6       0.20      0.09      0.13      5398\n",
      "           7       0.60      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1498   25 1012  544 1062  363  513  381]\n",
      " [  70 4532    7  122  465  168   12   22]\n",
      " [ 545   22 1967  979  296  777  467  345]\n",
      " [ 369   51 1073 1418  749 1179  347  212]\n",
      " [ 692   14  293  668 2429  556  347  399]\n",
      " [  83   58  604  882  703 2840  130   98]\n",
      " [ 922   59 1019  953 1239  426  510  270]\n",
      " [ 520    6  681  365  684  364  224 2554]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.29      0.36      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.09      0.13      5398\n",
      "           7       0.59      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1498   25 1001  545 1068  363  499  399]\n",
      " [  70 4532    7  122  465  168   12   22]\n",
      " [ 571   22 1933  993  296  774  462  347]\n",
      " [ 382   49 1052 1461  782 1149  317  206]\n",
      " [ 687   13  289  675 2443  553  339  399]\n",
      " [  88   56  599  925  705 2802  124   99]\n",
      " [ 923   57 1004  942 1254  427  502  289]\n",
      " [ 525    6  678  363  684  364  218 2560]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.95      0.84      0.89      5398\n",
      "           2       0.29      0.36      0.32      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.20      0.09      0.13      5398\n",
      "           7       0.59      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1495   25 1011  546 1064  365  499  393]\n",
      " [  70 4532    7  122  465  168   12   22]\n",
      " [ 567   22 1922 1004  298  783  462  340]\n",
      " [ 382   49 1030 1456  786 1174  317  204]\n",
      " [ 686   13  289  689 2416  567  339  399]\n",
      " [  88   56  588  933  696 2815  124   98]\n",
      " [ 916   57  991  952 1251  433  502  296]\n",
      " [ 525    6  686  363  684  365  218 2551]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.97      0.84      0.90      5398\n",
      "           2       0.29      0.36      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.42      0.52      0.47      5398\n",
      "           6       0.21      0.10      0.13      5398\n",
      "           7       0.59      0.47      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1508   21  999  536 1055  371  501  407]\n",
      " [  70 4532    7  122  465  168   12   22]\n",
      " [ 574   15 1938  998  283  782  466  342]\n",
      " [ 381   29 1048 1474  774 1162  325  205]\n",
      " [ 692   13  296  699 2406  558  334  400]\n",
      " [  89   25  623  927  696 2806  139   93]\n",
      " [ 922   25 1008  938 1245  433  521  306]\n",
      " [ 525    6  674  368  681  374  220 2550]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30      5398\n",
      "           1       0.98      0.84      0.90      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.55      0.48      5398\n",
      "           6       0.21      0.10      0.14      5398\n",
      "           7       0.60      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1509   21  966  548 1051  376  519  408]\n",
      " [  70 4518    7  122  465  182   12   22]\n",
      " [ 564   14 1852 1057  281  811  498  321]\n",
      " [ 377   16 1025 1478  776 1183  339  204]\n",
      " [ 690    7  290  699 2430  536  346  400]\n",
      " [  91    2  505  922  703 2975  139   61]\n",
      " [ 923   23  975  935 1255  422  558  307]\n",
      " [ 529    5  644  370  682  399  222 2547]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29      5398\n",
      "           1       0.98      0.84      0.90      5398\n",
      "           2       0.30      0.34      0.32      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.44      0.55      0.49      5398\n",
      "           6       0.21      0.10      0.14      5398\n",
      "           7       0.60      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1478   21  967  550 1075  376  528  403]\n",
      " [  70 4518    7  108  470  191   12   22]\n",
      " [ 562   14 1847 1054  288  827  494  312]\n",
      " [ 398   16 1020 1489  784 1165  321  205]\n",
      " [ 687    7  288  702 2440  509  356  409]\n",
      " [  91    2  495  924  707 2981  139   59]\n",
      " [ 920   23  978  929 1276  402  562  308]\n",
      " [ 534    5  647  378  661  401  229 2543]]\n",
      "Min_samples_leaf : 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.98      0.84      0.90      5398\n",
      "           2       0.29      0.33      0.31      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.44      0.37      5398\n",
      "           5       0.44      0.56      0.49      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.60      0.47      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1521   21  949  552 1028  394  537  396]\n",
      " [  70 4518    7   99  473  197   12   22]\n",
      " [ 620   14 1804 1067  252  820  524  297]\n",
      " [ 444   16 1018 1469  750 1181  337  183]\n",
      " [ 698    7  283  707 2401  516  358  428]\n",
      " [ 101    2  530  858  679 3016  149   63]\n",
      " [ 928   23  982  919 1248  412  582  304]\n",
      " [ 544    5  658  376  647  397  241 2530]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.30      5398\n",
      "           1       0.98      0.84      0.90      5398\n",
      "           2       0.29      0.33      0.31      5398\n",
      "           3       0.25      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.38      5398\n",
      "           5       0.43      0.56      0.49      5398\n",
      "           6       0.21      0.11      0.14      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1520   21  948  521 1056  408  526  398]\n",
      " [  71 4518    7   84  487  197   12   22]\n",
      " [ 604   14 1797 1060  257  871  514  281]\n",
      " [ 421   16 1004 1455  777 1198  347  180]\n",
      " [ 682    7  272  670 2452  521  376  418]\n",
      " [ 105    2  506  873  671 3024  149   68]\n",
      " [ 944   23  982  872 1267  414  584  312]\n",
      " [ 554    5  655  364  658  410  244 2508]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.29      0.33      0.31      5398\n",
      "           3       0.25      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.56      0.49      5398\n",
      "           6       0.21      0.10      0.14      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1525   22  948  528 1052  409  516  398]\n",
      " [  71 4518    7   84  487  197   12   22]\n",
      " [ 616   53 1773 1056  257  871  491  281]\n",
      " [ 431   32  991 1453  774 1198  338  181]\n",
      " [ 710    7  273  686 2418  521  364  419]\n",
      " [  99   34  487  871  679 3023  137   68]\n",
      " [ 954   45  996  869 1260  414  548  312]\n",
      " [ 542    5  652  371  663  410  247 2508]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.29      0.33      0.31      5398\n",
      "           3       0.24      0.27      0.25      5398\n",
      "           4       0.32      0.45      0.38      5398\n",
      "           5       0.43      0.56      0.48      5398\n",
      "           6       0.21      0.10      0.13      5398\n",
      "           7       0.60      0.47      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1497   22  986  523 1056  407  502  405]\n",
      " [  71 4518    7   84  487  197   12   22]\n",
      " [ 598   53 1785 1051  258  882  490  281]\n",
      " [ 405   32 1011 1436  775 1236  322  181]\n",
      " [ 703    7  271  679 2446  532  340  420]\n",
      " [  99   34  482  885  700 3020  115   63]\n",
      " [ 930   45 1006  894 1263  413  525  322]\n",
      " [ 543    5  664  365  660  412  236 2513]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.33      0.31      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.46      0.38      5398\n",
      "           5       0.43      0.56      0.48      5398\n",
      "           6       0.21      0.09      0.13      5398\n",
      "           7       0.60      0.47      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1506   22  986  530 1062  413  474  405]\n",
      " [  75 4518    7   84  483  197   12   22]\n",
      " [ 611   53 1775 1105  255  872  446  281]\n",
      " [ 406   32 1023 1463  779 1211  303  181]\n",
      " [ 705    7  271  681 2463  538  314  419]\n",
      " [  99   34  498  882  691 3024  107   63]\n",
      " [ 933   45 1006  901 1275  419  498  321]\n",
      " [ 533    5  667  364  657  425  234 2513]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.33      0.31      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.46      0.38      5398\n",
      "           5       0.43      0.56      0.48      5398\n",
      "           6       0.21      0.10      0.13      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1485   22  995  530 1062  414  486  404]\n",
      " [  75 4518    7   84  487  197   12   18]\n",
      " [ 606   53 1779 1106  258  869  446  281]\n",
      " [ 403   32 1029 1463  801 1214  300  156]\n",
      " [ 685    7  272  680 2485  531  332  406]\n",
      " [  99   34  499  882  699 3016  106   63]\n",
      " [ 906   45 1009  901 1291  418  514  314]\n",
      " [ 529    5  672  364  684  423  234 2487]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.30      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.33      0.30      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.56      0.48      5398\n",
      "           6       0.21      0.09      0.12      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1532   22 1009  524 1039  413  452  407]\n",
      " [  75 4518    7   84  487  197   12   18]\n",
      " [ 631   53 1761 1130  251  869  423  280]\n",
      " [ 407   32 1022 1478  790 1214  304  151]\n",
      " [ 727    7  272  689 2440  531  300  432]\n",
      " [  99   34  497  884  699 3016  106   63]\n",
      " [ 935   45 1013  904 1290  418  472  321]\n",
      " [ 553    5  666  375  650  423  228 2498]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.33      0.30      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.45      0.37      5398\n",
      "           5       0.43      0.56      0.49      5398\n",
      "           6       0.21      0.09      0.12      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1508   22 1015  535 1041  387  475  415]\n",
      " [  75 4518    7   81  487  200   12   18]\n",
      " [ 634   53 1787 1129  252  835  429  279]\n",
      " [ 409   32 1044 1485  778 1188  311  151]\n",
      " [ 710    7  290  713 2411  521  314  432]\n",
      " [ 112   34  523  883  680 3001  104   61]\n",
      " [ 907   45 1028  907 1288  423  483  317]\n",
      " [ 553    5  673  388  647  416  225 2491]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.33      0.31      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.32      0.44      0.37      5398\n",
      "           5       0.43      0.56      0.49      5398\n",
      "           6       0.21      0.09      0.12      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1529   22 1015  525 1041  387  464  415]\n",
      " [  75 4518    7   81  487  200   12   18]\n",
      " [ 638   53 1782 1131  251  836  428  279]\n",
      " [ 415   32 1009 1514  776 1190  311  151]\n",
      " [ 723    7  286  706 2372  560  312  432]\n",
      " [ 112   34  488  918  665 3016  104   61]\n",
      " [ 913   45 1014  918 1284  428  479  317]\n",
      " [ 567    5  666  387  641  422  219 2491]]\n",
      "Min_samples_leaf : 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.32      0.30      5398\n",
      "           3       0.25      0.28      0.26      5398\n",
      "           4       0.31      0.44      0.37      5398\n",
      "           5       0.43      0.56      0.48      5398\n",
      "           6       0.20      0.09      0.12      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1501   22 1017  520 1053  392  477  416]\n",
      " [  75 4518    7   81  487  200   12   18]\n",
      " [ 617   53 1751 1132  256  866  431  292]\n",
      " [ 410   32  981 1535  783 1199  310  148]\n",
      " [ 706    7  286  704 2385  560  329  421]\n",
      " [ 112   34  464  942  660 3016  118   52]\n",
      " [ 899   45 1003  929 1299  429  487  307]\n",
      " [ 533    5  659  394  664  424  231 2488]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.96      0.84      0.89      5398\n",
      "           2       0.28      0.32      0.30      5398\n",
      "           3       0.24      0.28      0.26      5398\n",
      "           4       0.31      0.44      0.37      5398\n",
      "           5       0.42      0.56      0.48      5398\n",
      "           6       0.21      0.09      0.13      5398\n",
      "           7       0.60      0.46      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1508   22 1014  519 1061  392  473  409]\n",
      " [  75 4518    7   76  487  205   12   18]\n",
      " [ 628   53 1741 1134  252  869  437  284]\n",
      " [ 441   32  978 1512  784 1220  308  123]\n",
      " [ 699    7  285  679 2392  581  323  432]\n",
      " [ 105   34  452  942  666 3023  114   62]\n",
      " [ 885   45 1003  932 1308  433  488  304]\n",
      " [ 540    5  651  394  661  429  225 2493]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Entropy\n",
    "for i in range(45,101):\n",
    "    dtc2_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1,criterion='entropy')\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc2_min_leaf=create_model(dtc2_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "143bacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      5398\n",
      "           1       0.92      0.84      0.88      5398\n",
      "           2       0.30      0.35      0.32      5398\n",
      "           3       0.24      0.27      0.26      5398\n",
      "           4       0.31      0.40      0.35      5398\n",
      "           5       0.44      0.49      0.46      5398\n",
      "           6       0.21      0.15      0.17      5398\n",
      "           7       0.60      0.49      0.54      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.41     43184\n",
      "weighted avg       0.42      0.41      0.41     43184\n",
      "\n",
      "[[1489   13  897  521 1018  271  755  434]\n",
      " [  51 4535   17  157  463  173    0    2]\n",
      " [ 547   31 1884  943  368  670  618  337]\n",
      " [ 489  117 1086 1466  648  999  410  183]\n",
      " [ 657   52  278  735 2149  493  610  424]\n",
      " [ 166  120  543  998  633 2631  220   87]\n",
      " [ 970   35  901  858 1121  381  795  337]\n",
      " [ 502    8  620  400  585  307  320 2656]]\n"
     ]
    }
   ],
   "source": [
    "#Min samples leaf pruning technique on DecisionTreeClassifier with Entropy\n",
    "#Min_samples_leaf=51 gives best recall = 0.80\n",
    "dtc2_min_leaf=DecisionTreeClassifier(min_samples_leaf=51,random_state=1,criterion='entropy')\n",
    "dtc2_min_leaf=create_model(dtc2_min_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92cdf5",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1152f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with RandomForestClassifier Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924270fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision Trees : 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.41      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.31      0.32      0.31      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.32      0.33      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.55      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2202    8  596  290  748  112  887  555]\n",
      " [ 141 4404   12  188  411  163   68   11]\n",
      " [1121   14 1711  771  252  393  755  381]\n",
      " [ 630   73  970 1496  610  760  608  251]\n",
      " [1139   20  328  585 1792  282  779  473]\n",
      " [ 511   64  539 1228  495 1988  398  175]\n",
      " [1464   13  844  659  804  199 1023  392]\n",
      " [ 844    5  513  264  455  147  487 2683]]\n",
      "No of decision Trees : 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.31      0.32      0.31      5398\n",
      "           3       0.28      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2178    7  604  277  741  106  911  574]\n",
      " [ 138 4405   13  193  404  167   65   13]\n",
      " [1112   12 1708  772  251  393  771  379]\n",
      " [ 640   71  959 1508  601  757  612  250]\n",
      " [1128   17  320  583 1816  281  782  471]\n",
      " [ 504   78  557 1221  495 1977  390  176]\n",
      " [1453   14  845  652  797  194 1036  407]\n",
      " [ 819    5  515  260  454  150  501 2694]]\n",
      "No of decision Trees : 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.41      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.31      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.43      5398\n",
      "           6       0.21      0.19      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.43      0.40      0.41     43184\n",
      "weighted avg       0.43      0.40      0.41     43184\n",
      "\n",
      "[[2188    7  600  288  735  106  902  572]\n",
      " [ 137 4405   16  194  405  163   64   14]\n",
      " [1079   16 1732  764  261  397  761  388]\n",
      " [ 625   59  948 1540  604  767  608  247]\n",
      " [1124   17  327  570 1830  284  787  459]\n",
      " [ 478   72  548 1213  475 2017  421  174]\n",
      " [1460   14  839  633  797  200 1043  412]\n",
      " [ 818    5  514  267  469  148  483 2694]]\n",
      "No of decision Trees : 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.31      0.32      0.31      5398\n",
      "           3       0.28      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2173    7  605  286  730  106  918  573]\n",
      " [ 138 4404   15  194  410  159   63   15]\n",
      " [1083   13 1705  782  258  398  769  390]\n",
      " [ 619   53  950 1530  604  805  592  245]\n",
      " [1109   16  325  581 1813  289  790  475]\n",
      " [ 482   72  537 1234  495 1994  408  176]\n",
      " [1438   11  834  666  803  203 1029  414]\n",
      " [ 809    5  509  272  454  151  488 2710]]\n",
      "No of decision Trees : 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.31      0.32      0.31      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.55      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.43      0.40      0.41     43184\n",
      "weighted avg       0.43      0.40      0.41     43184\n",
      "\n",
      "[[2178    7  606  297  722  110  909  569]\n",
      " [ 134 4402   14  198  411  160   64   15]\n",
      " [1090   13 1707  786  256  395  763  388]\n",
      " [ 612   57  930 1549  602  804  609  235]\n",
      " [1101   13  315  588 1837  280  800  464]\n",
      " [ 491   64  523 1233  491 2012  404  180]\n",
      " [1414   10  843  650  813  196 1054  418]\n",
      " [ 787    6  519  271  466  152  477 2720]]\n",
      "No of decision Trees : 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.19      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2164    8  605  297  723  110  916  575]\n",
      " [ 131 4403   14  193  424  154   65   14]\n",
      " [1059   13 1715  789  263  392  770  397]\n",
      " [ 607   60  907 1540  597  816  624  247]\n",
      " [1104   13  319  579 1820  279  805  479]\n",
      " [ 481   60  518 1242  476 2038  402  181]\n",
      " [1428   10  843  643  816  198 1049  411]\n",
      " [ 791    7  505  275  458  157  481 2724]]\n",
      "No of decision Trees : 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2165    8  602  284  723  114  926  576]\n",
      " [ 131 4403   12  178  429  155   71   19]\n",
      " [1057   11 1728  788  255  394  765  400]\n",
      " [ 608   57  885 1551  609  816  630  242]\n",
      " [1079   13  305  586 1826  275  818  496]\n",
      " [ 478   67  497 1229  496 2043  409  179]\n",
      " [1439   10  848  632  794  197 1065  413]\n",
      " [ 787    6  503  275  473  158  474 2722]]\n",
      "No of decision Trees : 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2171    8  602  287  729  110  920  571]\n",
      " [ 130 4403   11  193  421  155   66   19]\n",
      " [1054   11 1696  795  264  399  779  400]\n",
      " [ 607   63  892 1543  605  827  625  236]\n",
      " [1078   13  312  589 1840  274  805  487]\n",
      " [ 486   67  490 1256  503 2010  409  177]\n",
      " [1426   11  847  632  803  204 1054  421]\n",
      " [ 782    6  501  274  473  154  474 2734]]\n",
      "No of decision Trees : 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.43      0.40      0.41     43184\n",
      "weighted avg       0.43      0.40      0.41     43184\n",
      "\n",
      "[[2158    8  598  282  727  112  939  574]\n",
      " [ 125 4405    6  195  424  164   61   18]\n",
      " [1060   12 1705  785  268  392  784  392]\n",
      " [ 618   57  877 1561  596  815  632  242]\n",
      " [1094   13  300  584 1822  279  812  494]\n",
      " [ 465   72  525 1244  497 2011  399  185]\n",
      " [1420    8  837  634  807  198 1077  417]\n",
      " [ 770    5  505  275  475  158  481 2729]]\n",
      "No of decision Trees : 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2165    9  599  282  724  109  932  578]\n",
      " [ 128 4406    8  190  428  161   57   20]\n",
      " [1045   12 1711  787  266  399  783  395]\n",
      " [ 609   57  898 1550  614  805  624  241]\n",
      " [1083   12  311  591 1823  278  808  492]\n",
      " [ 469   66  523 1254  519 2009  379  179]\n",
      " [1419    9  835  637  797  201 1073  427]\n",
      " [ 760    5  516  284  476  154  487 2716]]\n",
      "No of decision Trees : 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.50      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.43      0.40      0.41     43184\n",
      "weighted avg       0.43      0.40      0.41     43184\n",
      "\n",
      "[[2166    7  590  281  735  111  938  570]\n",
      " [ 129 4402    6  195  432  155   62   17]\n",
      " [1033   13 1723  792  257  391  793  396]\n",
      " [ 607   55  885 1563  615  802  626  245]\n",
      " [1066   11  300  594 1827  283  814  503]\n",
      " [ 453   66  508 1275  502 2011  404  179]\n",
      " [1420    8  838  633  799  203 1080  417]\n",
      " [ 771    6  510  276  474  156  489 2716]]\n",
      "No of decision Trees : 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.43      0.40      0.41     43184\n",
      "weighted avg       0.43      0.40      0.41     43184\n",
      "\n",
      "[[2159    7  595  276  728  110  950  573]\n",
      " [ 123 4405   11  198  429  153   63   16]\n",
      " [1037   13 1711  807  256  391  797  386]\n",
      " [ 594   55  893 1562  600  818  622  254]\n",
      " [1064   10  307  591 1831  284  798  513]\n",
      " [ 446   62  508 1276  497 2030  404  175]\n",
      " [1427    8  844  632  801  205 1060  421]\n",
      " [ 758    6  515  283  469  153  486 2728]]\n",
      "No of decision Trees : 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2161    7  600  284  730  105  944  567]\n",
      " [ 128 4404    8  192  432  156   62   16]\n",
      " [1045   13 1717  795  262  381  797  388]\n",
      " [ 594   51  902 1539  606  820  628  258]\n",
      " [1073   10  310  598 1814  278  812  503]\n",
      " [ 451   61  506 1280  517 2010  388  185]\n",
      " [1419    7  832  646  802  206 1067  419]\n",
      " [ 752    5  503  282  475  152  487 2742]]\n",
      "No of decision Trees : 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2152    7  590  281  745  107  938  578]\n",
      " [ 128 4405    5  198  435  153   57   17]\n",
      " [1056   14 1694  809  266  389  793  377]\n",
      " [ 582   48  896 1559  616  825  613  259]\n",
      " [1079   10  298  591 1831  272  806  511]\n",
      " [ 442   64  515 1270  508 2023  404  172]\n",
      " [1431    9  837  642  804  208 1046  421]\n",
      " [ 754    7  505  280  475  154  485 2738]]\n",
      "No of decision Trees : 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.37      0.42      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2146    7  598  281  737  109  943  577]\n",
      " [ 126 4402    6  185  438  159   64   18]\n",
      " [1027   13 1706  807  274  387  795  389]\n",
      " [ 581   48  903 1543  625  808  627  263]\n",
      " [1072   10  293  596 1838  270  802  517]\n",
      " [ 446   62  517 1259  506 2020  410  178]\n",
      " [1398    8  843  653  800  208 1062  426]\n",
      " [ 753    6  507  275  474  153  491 2739]]\n",
      "No of decision Trees : 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.40     43184\n",
      "   macro avg       0.42      0.40      0.41     43184\n",
      "weighted avg       0.42      0.40      0.41     43184\n",
      "\n",
      "[[2148    7  587  289  743  107  929  588]\n",
      " [ 129 4404    4  189  434  156   63   19]\n",
      " [1037   14 1704  819  263  379  794  388]\n",
      " [ 583   45  893 1544  621  819  631  262]\n",
      " [1066   10  293  600 1828  277  814  510]\n",
      " [ 444   60  524 1252  506 2036  396  180]\n",
      " [1408    8  837  654  808  204 1058  421]\n",
      " [ 750    6  514  279  471  152  492 2734]]\n",
      "No of decision Trees : 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2156    7  590  287  733  111  928  586]\n",
      " [ 132 4403    5  197  426  153   63   19]\n",
      " [1045   15 1729  808  262  371  782  386]\n",
      " [ 580   45  887 1565  612  822  633  254]\n",
      " [1061   11  279  599 1850  275  807  516]\n",
      " [ 439   61  506 1247  518 2043  400  184]\n",
      " [1396    8  838  650  813  209 1064  420]\n",
      " [ 751    6  508  282  470  149  496 2736]]\n",
      "No of decision Trees : 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2147    7  604  287  729  107  936  581]\n",
      " [ 133 4402    6  190  434  152   62   19]\n",
      " [1037   12 1732  805  268  376  785  383]\n",
      " [ 586   45  891 1543  609  832  636  256]\n",
      " [1063   10  279  599 1842  273  813  519]\n",
      " [ 446   62  518 1238  509 2051  391  183]\n",
      " [1395    6  842  651  829  202 1053  420]\n",
      " [ 760    6  506  277  462  148  491 2748]]\n",
      "No of decision Trees : 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2142    7  597  284  731  108  941  588]\n",
      " [ 137 4402    5  187  433  152   64   18]\n",
      " [1031   13 1727  805  274  374  788  386]\n",
      " [ 590   44  904 1517  614  832  636  261]\n",
      " [1063   10  277  592 1849  274  814  519]\n",
      " [ 439   60  507 1241  509 2061  395  186]\n",
      " [1399    6  833  647  830  204 1058  421]\n",
      " [ 750    7  513  276  456  150  489 2757]]\n",
      "No of decision Trees : 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.49      0.37      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2154    7  596  283  736  106  932  584]\n",
      " [ 139 4403    6  181  432  152   63   22]\n",
      " [1031   12 1729  804  270  371  798  383]\n",
      " [ 577   44  904 1525  610  824  649  265]\n",
      " [1075   11  279  580 1860  274  809  510]\n",
      " [ 446   60  516 1272  517 2024  382  181]\n",
      " [1411    6  823  651  824  204 1060  419]\n",
      " [ 747    7  507  285  454  148  489 2761]]\n",
      "No of decision Trees : 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2138    7  607  283  735  107  926  595]\n",
      " [ 140 4401    5  184  433  151   65   19]\n",
      " [1027   13 1744  795  273  375  782  389]\n",
      " [ 581   44  898 1523  612  829  641  270]\n",
      " [1074   11  286  585 1861  273  796  512]\n",
      " [ 446   58  510 1284  508 2028  376  188]\n",
      " [1404    6  829  652  823  201 1066  417]\n",
      " [ 751    7  499  285  464  150  479 2763]]\n",
      "No of decision Trees : 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2151    7  604  285  730  108  928  585]\n",
      " [ 137 4401    4  181  438  152   63   22]\n",
      " [1034   14 1734  795  270  378  786  387]\n",
      " [ 575   44  906 1519  620  831  636  267]\n",
      " [1081   11  281  579 1857  277  809  503]\n",
      " [ 443   61  516 1250  519 2043  380  186]\n",
      " [1397    6  830  656  826  205 1064  414]\n",
      " [ 743    9  503  287  461  148  483 2764]]\n",
      "No of decision Trees : 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2147    7  599  288  733  109  931  584]\n",
      " [ 143 4401    6  175  433  149   68   23]\n",
      " [1040   13 1732  800  262  378  789  384]\n",
      " [ 577   46  897 1516  622  823  635  282]\n",
      " [1082   10  283  588 1852  276  799  508]\n",
      " [ 455   60  516 1234  505 2048  388  192]\n",
      " [1404    6  836  641  825  207 1058  421]\n",
      " [ 738    7  499  285  464  152  487 2766]]\n",
      "No of decision Trees : 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.28      0.28      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2156    7  603  283  721  110  940  578]\n",
      " [ 142 4402    8  170  433  150   71   22]\n",
      " [1046   16 1729  804  260  379  782  382]\n",
      " [ 572   47  882 1526  620  837  639  275]\n",
      " [1062   10  280  586 1864  273  821  502]\n",
      " [ 457   65  508 1243  497 2055  387  186]\n",
      " [1416    6  816  643  833  208 1057  419]\n",
      " [ 743    7  498  283  464  153  484 2766]]\n",
      "No of decision Trees : 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2154    7  603  282  730  108  933  581]\n",
      " [ 142 4400   10  175  432  147   69   23]\n",
      " [1031   15 1722  818  262  375  794  381]\n",
      " [ 570   47  895 1521  611  844  638  272]\n",
      " [1061   10  283  586 1852  277  816  513]\n",
      " [ 464   64  508 1229  494 2062  388  189]\n",
      " [1406    6  829  643  829  205 1055  425]\n",
      " [ 741    8  502  285  462  154  478 2768]]\n",
      "No of decision Trees : 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2134    7  612  289  733  108  934  581]\n",
      " [ 142 4401    9  176  429  149   70   22]\n",
      " [1020   15 1738  811  263  369  799  383]\n",
      " [ 568   45  879 1521  615  845  652  273]\n",
      " [1059   10  281  587 1860  274  828  499]\n",
      " [ 459   61  510 1244  487 2056  391  190]\n",
      " [1398    9  838  647  823  207 1057  419]\n",
      " [ 751    7  499  285  460  152  478 2766]]\n",
      "No of decision Trees : 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2144    7  606  285  733  105  938  580]\n",
      " [ 142 4401   10  176  429  148   72   20]\n",
      " [1023   14 1736  828  258  371  788  380]\n",
      " [ 564   48  885 1527  615  846  638  275]\n",
      " [1060   10  278  591 1863  274  818  504]\n",
      " [ 461   64  510 1233  483 2069  391  187]\n",
      " [1398    9  841  651  830  208 1044  417]\n",
      " [ 745    7  502  286  461  150  483 2764]]\n",
      "No of decision Trees : 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.27      0.28      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.43      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2134    7  609  286  733  107  938  584]\n",
      " [ 142 4400   10  180  429  149   70   18]\n",
      " [1032   14 1729  810  263  367  795  388]\n",
      " [ 565   49  879 1528  618  845  638  276]\n",
      " [1067   10  273  597 1856  279  813  503]\n",
      " [ 457   66  503 1240  471 2084  390  187]\n",
      " [1400    9  842  648  831  211 1043  414]\n",
      " [ 752    8  500  284  453  148  485 2768]]\n",
      "No of decision Trees : 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2136    7  608  288  735  107  942  575]\n",
      " [ 141 4400   10  178  424  152   72   21]\n",
      " [1043   13 1736  816  255  365  784  386]\n",
      " [ 558   46  884 1539  616  844  639  272]\n",
      " [1055   11  274  595 1846  284  823  510]\n",
      " [ 462   61  497 1238  471 2077  402  190]\n",
      " [1397    9  845  641  831  213 1050  412]\n",
      " [ 754    9  504  280  449  149  481 2772]]\n",
      "No of decision Trees : 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2138    7  611  287  734  108  936  577]\n",
      " [ 142 4400   10  177  427  150   71   21]\n",
      " [1039   15 1729  810  252  365  804  384]\n",
      " [ 557   47  881 1547  617  840  643  266]\n",
      " [1061   11  274  595 1848  282  822  505]\n",
      " [ 456   58  504 1235  479 2078  395  193]\n",
      " [1396    8  829  657  835  213 1047  413]\n",
      " [ 758    8  504  283  443  148  481 2773]]\n",
      "No of decision Trees : 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2135    7  609  287  732  106  944  578]\n",
      " [ 140 4400   10  177  428  151   71   21]\n",
      " [1049   15 1721  826  247  362  799  379]\n",
      " [ 549   45  885 1559  611  856  625  268]\n",
      " [1064   10  266  600 1852  284  822  500]\n",
      " [ 463   55  507 1232  475 2074  398  194]\n",
      " [1405    9  826  651  836  210 1051  410]\n",
      " [ 742    7  503  279  447  145  489 2786]]\n",
      "No of decision Trees : 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.82      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.39      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2128    8  607  282  737  106  952  578]\n",
      " [ 141 4400    6  176  426  153   73   23]\n",
      " [1042   14 1724  830  254  364  790  380]\n",
      " [ 550   45  880 1563  614  857  624  265]\n",
      " [1066   11  265  594 1847  290  821  504]\n",
      " [ 453   57  504 1236  474 2085  403  186]\n",
      " [1415    8  822  646  828  208 1059  412]\n",
      " [ 751    7  505  276  451  147  487 2774]]\n",
      "No of decision Trees : 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2121    8  601  286  737  107  952  586]\n",
      " [ 139 4399    6  177  424  154   76   23]\n",
      " [1046   13 1713  826  255  359  802  384]\n",
      " [ 544   44  879 1565  617  855  624  270]\n",
      " [1048   11  269  591 1852  291  826  510]\n",
      " [ 453   57  509 1233  480 2071  403  192]\n",
      " [1411    8  827  642  831  206 1062  411]\n",
      " [ 748    7  501  280  456  146  474 2786]]\n",
      "No of decision Trees : 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.39      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2114    8  606  285  737  107  954  587]\n",
      " [ 141 4398    6  178  425  154   73   23]\n",
      " [1045   14 1700  824  255  365  810  385]\n",
      " [ 547   45  875 1564  622  850  623  272]\n",
      " [1048   11  274  596 1842  287  824  516]\n",
      " [ 457   57  505 1229  478 2082  397  193]\n",
      " [1418    8  813  642  834  205 1067  411]\n",
      " [ 750    8  500  280  450  146  488 2776]]\n",
      "No of decision Trees : 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2125    8  607  282  745  107  943  581]\n",
      " [ 139 4398    7  179  425  155   72   23]\n",
      " [1044   13 1703  832  259  366  796  385]\n",
      " [ 549   47  871 1572  621  846  624  268]\n",
      " [1045   11  276  596 1855  284  814  517]\n",
      " [ 461   59  505 1238  481 2061  401  192]\n",
      " [1411    8  816  649  832  204 1065  413]\n",
      " [ 753    8  505  270  458  148  482 2774]]\n",
      "No of decision Trees : 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2122    8  599  285  744  106  951  583]\n",
      " [ 141 4398    7  181  424  154   69   24]\n",
      " [1048   11 1703  836  254  368  792  386]\n",
      " [ 543   45  881 1558  624  852  622  273]\n",
      " [1045   11  274  593 1849  282  827  517]\n",
      " [ 462   60  504 1234  486 2056  404  192]\n",
      " [1413    8  823  646  827  204 1067  410]\n",
      " [ 753    8  499  275  448  146  491 2778]]\n",
      "No of decision Trees : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2122    8  596  283  749  107  948  585]\n",
      " [ 142 4399    6  176  426  154   71   24]\n",
      " [1023   11 1699  834  259  371  814  387]\n",
      " [ 547   43  888 1564  617  856  612  271]\n",
      " [1053   11  273  592 1847  286  816  520]\n",
      " [ 463   59  510 1221  487 2067  400  191]\n",
      " [1408    7  826  645  830  200 1071  411]\n",
      " [ 755    8  501  274  456  143  485 2776]]\n",
      "No of decision Trees : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.32      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2124    7  597  286  757  107  941  579]\n",
      " [ 143 4398    6  179  425  153   70   24]\n",
      " [1023   11 1710  834  259  369  804  388]\n",
      " [ 542   44  883 1577  611  854  616  271]\n",
      " [1054   11  273  589 1840  284  826  521]\n",
      " [ 460   59  504 1215  487 2076  402  195]\n",
      " [1411    9  823  648  826  202 1068  411]\n",
      " [ 755    8  498  275  458  146  482 2776]]\n",
      "No of decision Trees : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2134    7  604  281  746  106  940  580]\n",
      " [ 144 4398    6  176  426  154   70   24]\n",
      " [1034   12 1704  830  259  364  807  388]\n",
      " [ 554   41  875 1577  609  854  617  271]\n",
      " [1043   11  273  591 1844  284  829  523]\n",
      " [ 460   60  502 1211  483 2072  416  194]\n",
      " [1413    9  830  645  832  202 1060  407]\n",
      " [ 741    6  507  274  458  148  481 2783]]\n",
      "No of decision Trees : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2135    8  602  279  743  106  936  589]\n",
      " [ 143 4398    6  177  424  154   72   24]\n",
      " [1023   11 1711  830  259  368  808  388]\n",
      " [ 549   41  885 1567  603  858  616  279]\n",
      " [1057   12  270  589 1840  285  829  516]\n",
      " [ 461   60  500 1227  482 2072  405  191]\n",
      " [1402    9  820  647  830  205 1075  410]\n",
      " [ 743    8  500  275  454  146  488 2784]]\n",
      "No of decision Trees : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2138    8  599  281  746  106  934  586]\n",
      " [ 142 4398    6  184  425  149   70   24]\n",
      " [1024   12 1712  825  258  373  804  390]\n",
      " [ 548   43  883 1565  614  853  617  275]\n",
      " [1053   12  272  587 1854  285  817  518]\n",
      " [ 464   60  507 1216  483 2073  408  187]\n",
      " [1407   11  818  641  836  205 1071  409]\n",
      " [ 738    9  500  277  457  147  491 2779]]\n",
      "No of decision Trees : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2126    8  602  273  743  106  948  592]\n",
      " [ 142 4398    7  182  429  150   67   23]\n",
      " [1024   11 1698  820  262  374  817  392]\n",
      " [ 543   40  889 1554  617  852  621  282]\n",
      " [1042   12  268  587 1863  281  823  522]\n",
      " [ 459   60  514 1226  482 2057  405  195]\n",
      " [1405    9  829  644  833  202 1075  401]\n",
      " [ 740    9  499  276  459  148  488 2779]]\n",
      "No of decision Trees : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.49      0.38      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2133    7  609  276  742  104  940  587]\n",
      " [ 142 4397    7  179  426  152   70   25]\n",
      " [1028   12 1703  826  257  372  813  387]\n",
      " [ 546   41  887 1557  614  858  618  277]\n",
      " [1049   11  269  586 1849  284  827  523]\n",
      " [ 459   57  508 1218  485 2074  402  195]\n",
      " [1409    9  826  644  825  203 1082  400]\n",
      " [ 745    9  504  276  456  147  482 2779]]\n",
      "No of decision Trees : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.33      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2126    8  606  271  747  105  947  588]\n",
      " [ 142 4398    8  179  424  151   71   25]\n",
      " [1029   11 1708  821  253  371  810  395]\n",
      " [ 543   40  881 1566  609  857  621  281]\n",
      " [1045   11  269  592 1848  281  830  522]\n",
      " [ 459   56  504 1215  480 2090  400  194]\n",
      " [1412    8  832  646  820  200 1079  401]\n",
      " [ 739    9  502  275  457  147  485 2784]]\n",
      "No of decision Trees : 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2134    9  613  273  745  106  930  588]\n",
      " [ 143 4396    8  182  431  148   65   25]\n",
      " [1018   10 1713  822  257  370  810  398]\n",
      " [ 544   42  879 1564  612  859  615  283]\n",
      " [1047   11  271  587 1851  280  829  522]\n",
      " [ 463   57  505 1220  473 2087  401  192]\n",
      " [1419    8  817  645  817  200 1086  406]\n",
      " [ 742    8  496  281  454  147  484 2786]]\n",
      "No of decision Trees : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2132    9  608  274  751  106  934  584]\n",
      " [ 144 4397    8  180  426  149   69   25]\n",
      " [1014   10 1714  820  261  369  816  394]\n",
      " [ 547   41  877 1560  615  859  616  283]\n",
      " [1047   12  264  592 1851  282  826  524]\n",
      " [ 461   57  498 1218  472 2090  406  196]\n",
      " [1407    8  824  643  816  204 1089  407]\n",
      " [ 742    8  498  281  450  147  487 2785]]\n",
      "No of decision Trees : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.41     43184\n",
      "weighted avg       0.43      0.41      0.41     43184\n",
      "\n",
      "[[2130    9  604  271  749  105  943  587]\n",
      " [ 142 4398    8  182  424  152   69   23]\n",
      " [1023   10 1707  822  254  369  815  398]\n",
      " [ 549   41  874 1565  622  852  614  281]\n",
      " [1048   12  266  587 1856  277  829  523]\n",
      " [ 464   57  504 1224  477 2079  405  188]\n",
      " [1403    8  824  641  823  203 1088  408]\n",
      " [ 741    8  502  276  450  148  488 2785]]\n",
      "No of decision Trees : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.28      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.43      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2137    9  598  269  754  107  942  582]\n",
      " [ 142 4398    8  180  423  151   71   25]\n",
      " [1014   10 1716  821  254  371  810  402]\n",
      " [ 544   43  882 1560  615  857  621  276]\n",
      " [1040   12  273  584 1864  278  820  527]\n",
      " [ 462   57  504 1222  471 2088  406  188]\n",
      " [1392    8  840  645  821  208 1077  407]\n",
      " [ 740    7  511  275  452  148  487 2778]]\n",
      "No of decision Trees : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2155    9  600  266  745  107  938  578]\n",
      " [ 142 4398    8  183  423  151   70   23]\n",
      " [1024   10 1703  814  253  374  818  402]\n",
      " [ 543   43  875 1568  619  850  624  276]\n",
      " [1032   12  277  595 1860  276  821  525]\n",
      " [ 457   56  503 1223  477 2092  400  190]\n",
      " [1400    8  828  648  819  208 1074  413]\n",
      " [ 745    8  504  272  451  149  482 2787]]\n",
      "No of decision Trees : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2154    8  604  265  741  109  933  584]\n",
      " [ 144 4398    8  180  422  149   72   25]\n",
      " [1025   10 1709  815  256  372  814  397]\n",
      " [ 547   44  879 1568  618  844  621  277]\n",
      " [1039   13  277  589 1861  273  821  525]\n",
      " [ 461   55  502 1216  475 2098  404  187]\n",
      " [1401    8  828  644  816  205 1085  411]\n",
      " [ 738    8  511  277  451  149  483 2781]]\n",
      "No of decision Trees : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2151    8  606  267  743  106  936  581]\n",
      " [ 143 4398    9  181  421  149   72   25]\n",
      " [1027   10 1717  808  257  373  813  393]\n",
      " [ 540   45  881 1581  608  843  622  278]\n",
      " [1035   11  278  587 1865  273  825  524]\n",
      " [ 461   57  502 1217  473 2097  401  190]\n",
      " [1409    8  827  646  819  207 1072  410]\n",
      " [ 749    8  505  276  453  149  480 2778]]\n",
      "No of decision Trees : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.52      0.53      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2154    8  606  266  743  104  938  579]\n",
      " [ 144 4399    8  178  424  152   68   25]\n",
      " [1027   10 1717  810  253  370  819  392]\n",
      " [ 557   45  879 1574  608  842  622  271]\n",
      " [1034   12  275  596 1860  270  826  525]\n",
      " [ 460   57  499 1225  475 2094  399  189]\n",
      " [1403    8  818  652  819  203 1081  414]\n",
      " [ 753    9  504  277  448  146  481 2780]]\n",
      "No of decision Trees : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.54      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2158    8  603  266  746  104  933  580]\n",
      " [ 145 4399    8  178  426  153   66   23]\n",
      " [1020   10 1713  815  253  371  823  393]\n",
      " [ 545   44  887 1578  609  838  623  274]\n",
      " [1034   12  275  593 1860  276  823  525]\n",
      " [ 463   56  499 1208  482 2095  402  193]\n",
      " [1406    8  823  652  811  202 1078  418]\n",
      " [ 753    8  503  281  450  146  486 2771]]\n",
      "No of decision Trees : 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2151    8  604  271  739  104  941  580]\n",
      " [ 144 4398    8  176  426  155   66   25]\n",
      " [1021   10 1709  811  255  373  824  395]\n",
      " [ 545   43  884 1578  615  836  617  280]\n",
      " [1044   12  270  593 1856  274  822  527]\n",
      " [ 462   55  494 1212  480 2104  400  191]\n",
      " [1405    8  821  655  810  207 1072  420]\n",
      " [ 751    9  508  277  451  147  482 2773]]\n",
      "No of decision Trees : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.21      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2143    8  608  273  746  104  936  580]\n",
      " [ 143 4398    7  175  426  157   68   24]\n",
      " [1026   11 1715  813  243  368  825  397]\n",
      " [ 540   43  892 1574  620  835  614  280]\n",
      " [1040   13  272  586 1860  277  824  526]\n",
      " [ 454   57  489 1220  474 2106  401  197]\n",
      " [1414    9  821  654  802  208 1073  417]\n",
      " [ 749    9  503  279  455  147  486 2770]]\n",
      "No of decision Trees : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2148    8  604  270  741  105  938  584]\n",
      " [ 142 4399    7  176  429  155   65   25]\n",
      " [1026   10 1712  816  244  368  825  397]\n",
      " [ 534   42  887 1578  620  840  618  279]\n",
      " [1039   12  269  591 1851  277  831  528]\n",
      " [ 454   58  488 1220  474 2103  402  199]\n",
      " [1403    9  822  652  812  210 1068  422]\n",
      " [ 749    9  507  278  453  147  484 2771]]\n",
      "No of decision Trees : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2152    8  605  273  741  103  935  581]\n",
      " [ 143 4396    8  174  430  157   65   25]\n",
      " [1016   10 1716  819  249  375  819  394]\n",
      " [ 544   43  880 1578  622  839  620  272]\n",
      " [1048   12  271  587 1851  273  834  522]\n",
      " [ 457   58  484 1218  478 2108  398  197]\n",
      " [1409    9  816  652  814  212 1061  425]\n",
      " [ 748    9  510  278  457  148  483 2765]]\n",
      "No of decision Trees : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2145    8  602  272  740  102  940  589]\n",
      " [ 144 4396    8  177  426  155   67   25]\n",
      " [1011   11 1712  812  257  374  823  398]\n",
      " [ 539   44  889 1584  619  842  607  274]\n",
      " [1040   12  272  585 1858  274  834  523]\n",
      " [ 457   56  487 1221  472 2105  402  198]\n",
      " [1414    9  817  651  815  212 1060  420]\n",
      " [ 751    9  504  276  453  150  478 2777]]\n",
      "No of decision Trees : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.31      0.32      5398\n",
      "           3       0.28      0.30      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2152    8  606  269  743  103  933  584]\n",
      " [ 144 4396    9  174  429  156   65   25]\n",
      " [1020   11 1700  822  250  374  820  401]\n",
      " [ 543   42  876 1594  614  841  610  278]\n",
      " [1044   11  269  591 1860  272  826  525]\n",
      " [ 459   56  480 1225  475 2101  400  202]\n",
      " [1413    9  811  649  820  209 1058  429]\n",
      " [ 744    9  505  281  455  149  475 2780]]\n",
      "No of decision Trees : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.30      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2158    8  602  271  738  102  933  586]\n",
      " [ 142 4396    9  174  430  156   66   25]\n",
      " [1012   11 1706  821  253  370  827  398]\n",
      " [ 548   41  871 1595  619  838  612  274]\n",
      " [1052   11  271  589 1858  273  821  523]\n",
      " [ 462   56  477 1222  475 2104  403  199]\n",
      " [1417    9  812  648  821  207 1057  427]\n",
      " [ 744    9  503  280  457  147  475 2783]]\n",
      "No of decision Trees : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2144    8  600  266  747  103  937  593]\n",
      " [ 143 4396    9  173  434  156   62   25]\n",
      " [1009    9 1711  828  246  371  823  401]\n",
      " [ 543   43  877 1592  616  842  616  269]\n",
      " [1040   11  268  589 1866  274  828  522]\n",
      " [ 462   54  482 1217  473 2104  406  200]\n",
      " [1412    9  823  653  816  206 1056  423]\n",
      " [ 746    8  501  280  461  146  477 2779]]\n",
      "No of decision Trees : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.33      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2141    8  605  273  740  102  936  593]\n",
      " [ 140 4396    9  176  431  155   66   25]\n",
      " [1010    9 1715  825  249  370  821  399]\n",
      " [ 546   42  873 1592  616  838  622  269]\n",
      " [1039   12  268  590 1863  277  827  522]\n",
      " [ 459   59  482 1218  472 2103  401  204]\n",
      " [1421    9  812  656  818  207 1050  425]\n",
      " [ 745    8  505  280  462  145  474 2779]]\n",
      "No of decision Trees : 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2142    8  609  271  736  101  938  593]\n",
      " [ 143 4396    7  176  433  155   63   25]\n",
      " [1016    9 1710  822  247  370  826  398]\n",
      " [ 548   41  877 1581  620  839  621  271]\n",
      " [1038   12  263  591 1858  274  838  524]\n",
      " [ 461   57  487 1223  470 2094  405  201]\n",
      " [1411   10  821  656  816  209 1053  422]\n",
      " [ 744    9  503  278  460  146  477 2781]]\n",
      "No of decision Trees : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2135    7  612  270  735  100  948  591]\n",
      " [ 144 4396    7  178  434  155   59   25]\n",
      " [1014    9 1717  824  246  367  819  402]\n",
      " [ 547   41  872 1590  622  839  619  268]\n",
      " [1038   12  268  591 1859  277  832  521]\n",
      " [ 462   60  494 1210  471 2098  400  203]\n",
      " [1405   10  821  654  823  208 1046  431]\n",
      " [ 740    8  502  276  460  148  481 2783]]\n",
      "No of decision Trees : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.19      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2143    7  611  273  735  100  939  590]\n",
      " [ 142 4396    9  175  430  156   65   25]\n",
      " [1021    9 1702  825  249  367  821  404]\n",
      " [ 543   40  881 1590  619  836  619  270]\n",
      " [1042   11  267  594 1863  274  827  520]\n",
      " [ 461   58  491 1206  479 2099  404  200]\n",
      " [1410   10  821  654  817  207 1051  428]\n",
      " [ 737    8  503  278  459  149  484 2780]]\n",
      "No of decision Trees : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2140    7  610  271  737  100  943  590]\n",
      " [ 142 4396    9  175  430  156   65   25]\n",
      " [1015    9 1711  826  246  367  823  401]\n",
      " [ 549   40  882 1578  619  837  621  272]\n",
      " [1039   11  269  591 1870  272  834  512]\n",
      " [ 463   56  490 1192  479 2110  404  204]\n",
      " [1410   10  813  660  814  208 1057  426]\n",
      " [ 733    8  501  279  462  150  487 2778]]\n",
      "No of decision Trees : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2142    7  613  272  731  100  941  592]\n",
      " [ 144 4396    9  173  438  155   58   25]\n",
      " [1013    9 1703  825  251  368  828  401]\n",
      " [ 547   40  875 1583  617  846  616  274]\n",
      " [1041   11  274  595 1863  272  832  510]\n",
      " [ 457   56  491 1205  478 2108  405  198]\n",
      " [1419   10  810  655  814  208 1056  426]\n",
      " [ 735    8  503  281  461  151  479 2780]]\n",
      "No of decision Trees : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.88      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2134    7  610  275  734  100  945  593]\n",
      " [ 143 4396    9  173  432  154   66   25]\n",
      " [1022   10 1704  823  247  368  825  399]\n",
      " [ 548   41  876 1581  620  840  618  274]\n",
      " [1038   11  273  591 1867  271  834  513]\n",
      " [ 461   57  495 1203  487 2093  402  200]\n",
      " [1413    9  814  655  813  202 1064  428]\n",
      " [ 739    8  503  279  459  151  481 2778]]\n",
      "No of decision Trees : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2147    7  606  274  738  100  936  590]\n",
      " [ 142 4396    9  171  431  157   67   25]\n",
      " [1019    9 1705  817  250  370  825  403]\n",
      " [ 548   38  871 1586  623  841  618  273]\n",
      " [1034   11  277  587 1871  272  835  511]\n",
      " [ 463   56  495 1208  479 2095  397  205]\n",
      " [1403    9  816  661  824  203 1059  423]\n",
      " [ 735    7  507  284  459  147  479 2780]]\n",
      "No of decision Trees : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2145    7  603  274  736  103  938  592]\n",
      " [ 141 4396   10  170  432  155   69   25]\n",
      " [1012    9 1711  816  252  369  832  397]\n",
      " [ 545   37  875 1587  621  842  615  276]\n",
      " [1032   11  276  589 1864  275  832  519]\n",
      " [ 454   58  495 1215  481 2094  402  199]\n",
      " [1416    7  816  658  822  202 1056  421]\n",
      " [ 735    8  503  286  463  146  479 2778]]\n",
      "No of decision Trees : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2148    7  602  275  736  102  934  594]\n",
      " [ 141 4396    9  171  435  156   65   25]\n",
      " [1010    9 1709  817  254  372  832  395]\n",
      " [ 546   37  868 1582  624  845  619  277]\n",
      " [1036   11  278  584 1873  274  827  515]\n",
      " [ 457   56  497 1220  482 2088  397  201]\n",
      " [1413    8  813  661  823  202 1064  414]\n",
      " [ 732    7  504  286  463  147  477 2782]]\n",
      "No of decision Trees : 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2145    7  598  271  740  102  933  602]\n",
      " [ 141 4396   10  173  435  154   64   25]\n",
      " [1015    9 1705  816  253  374  826  400]\n",
      " [ 550   36  874 1576  625  842  613  282]\n",
      " [1038   11  276  588 1865  273  829  518]\n",
      " [ 459   56  497 1220  472 2092  400  202]\n",
      " [1419    8  807  659  822  205 1063  415]\n",
      " [ 740    7  505  282  464  145  481 2774]]\n",
      "No of decision Trees : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.30      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2151    7  600  270  741  103  931  595]\n",
      " [ 141 4396    9  174  436  153   64   25]\n",
      " [1018   10 1705  807  255  374  828  401]\n",
      " [ 551   36  866 1593  620  839  617  276]\n",
      " [1030   11  278  583 1863  276  836  521]\n",
      " [ 457   58  496 1221  481 2084  401  200]\n",
      " [1420    8  812  659  824  201 1058  416]\n",
      " [ 736    7  506  287  464  144  478 2776]]\n",
      "No of decision Trees : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.33      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2144    7  598  274  743  103  933  596]\n",
      " [ 143 4396    8  173  435  151   67   25]\n",
      " [1014   11 1713  815  252  373  822  398]\n",
      " [ 552   36  872 1591  620  839  611  277]\n",
      " [1032   11  277  586 1866  276  832  518]\n",
      " [ 453   57  493 1209  476 2095  408  207]\n",
      " [1422    8  805  662  822  200 1059  420]\n",
      " [ 737    7  503  282  459  146  484 2780]]\n",
      "No of decision Trees : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2146    7  603  272  741  103  928  598]\n",
      " [ 144 4395    8  170  435  155   66   25]\n",
      " [1020   11 1711  813  249  375  822  397]\n",
      " [ 550   36  868 1590  626  839  611  278]\n",
      " [1036   11  278  584 1868  277  826  518]\n",
      " [ 453   57  492 1212  476 2102  401  205]\n",
      " [1427    7  808  662  818  198 1057  421]\n",
      " [ 739    7  505  282  464  145  480 2776]]\n",
      "No of decision Trees : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2141    7  599  276  742  100  939  594]\n",
      " [ 143 4395    9  173  432  154   67   25]\n",
      " [1025   11 1709  814  251  369  825  394]\n",
      " [ 549   36  863 1585  624  842  620  279]\n",
      " [1031   10  280  586 1865  276  831  519]\n",
      " [ 452   57  497 1214  471 2102  402  203]\n",
      " [1422    7  803  668  815  201 1061  421]\n",
      " [ 741    7  505  286  464  144  474 2777]]\n",
      "No of decision Trees : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2140    7  598  273  747  100  940  593]\n",
      " [ 143 4395    9  171  435  154   66   25]\n",
      " [1015   11 1706  821  254  372  823  396]\n",
      " [ 553   36  857 1581  630  843  619  279]\n",
      " [1035   10  279  592 1858  281  823  520]\n",
      " [ 449   57  502 1206  475 2101  403  205]\n",
      " [1425    7  807  663  821  201 1058  416]\n",
      " [ 738    7  504  286  464  147  473 2779]]\n",
      "No of decision Trees : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.52      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2140    7  599  270  745  100  941  596]\n",
      " [ 143 4397    9  170  432  153   68   26]\n",
      " [1014   11 1709  823  251  374  822  394]\n",
      " [ 547   36  863 1580  619  850  625  278]\n",
      " [1043   10  280  588 1860  280  820  517]\n",
      " [ 449   58  499 1207  475 2101  404  205]\n",
      " [1419    7  812  662  822  200 1059  417]\n",
      " [ 741    6  502  287  462  147  472 2781]]\n",
      "No of decision Trees : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.35      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2147    7  600  270  746   98  934  596]\n",
      " [ 143 4396    8  172  430  153   70   26]\n",
      " [1015   11 1711  814  252  375  822  398]\n",
      " [ 548   36  862 1581  619  853  626  273]\n",
      " [1046   10  280  587 1866  279  817  513]\n",
      " [ 445   58  502 1209  472 2104  404  204]\n",
      " [1412    7  808  661  826  204 1060  420]\n",
      " [ 744    6  505  285  462  150  469 2777]]\n",
      "No of decision Trees : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2147    7  602  269  745   98  934  596]\n",
      " [ 143 4396    9  170  425  154   75   26]\n",
      " [1017   11 1707  815  253  373  825  397]\n",
      " [ 556   36  868 1579  619  846  621  273]\n",
      " [1039   11  283  590 1858  281  824  512]\n",
      " [ 452   57  494 1205  477 2107  405  201]\n",
      " [1402    8  813  663  829  201 1062  420]\n",
      " [ 743    7  506  283  462  148  471 2778]]\n",
      "No of decision Trees : 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2148    7  602  270  750   98  931  592]\n",
      " [ 142 4396   10  169  423  155   77   26]\n",
      " [1014   11 1705  821  254  373  823  397]\n",
      " [ 552   36  867 1579  617  857  619  271]\n",
      " [1035   11  281  593 1859  280  824  515]\n",
      " [ 451   58  494 1204  478 2103  406  204]\n",
      " [1410    8  812  661  824  202 1060  421]\n",
      " [ 741    7  507  284  462  147  471 2779]]\n",
      "No of decision Trees : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33      5398\n",
      "           1       0.97      0.81      0.89      5398\n",
      "           2       0.32      0.32      0.32      5398\n",
      "           3       0.28      0.29      0.29      5398\n",
      "           4       0.33      0.34      0.34      5398\n",
      "           5       0.50      0.39      0.44      5398\n",
      "           6       0.20      0.20      0.20      5398\n",
      "           7       0.53      0.51      0.52      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.43      0.41      0.42     43184\n",
      "weighted avg       0.43      0.41      0.42     43184\n",
      "\n",
      "[[2140    7  603  271  744   98  937  598]\n",
      " [ 143 4396   10  174  426  150   73   26]\n",
      " [1024   11 1702  822  249  374  820  396]\n",
      " [ 550   36  866 1577  619  856  621  273]\n",
      " [1032   11  281  592 1857  280  825  520]\n",
      " [ 448   57  493 1209  472 2106  411  202]\n",
      " [1407    8  816  661  827  200 1060  419]\n",
      " [ 743    7  510  282  468  150  465 2773]]\n",
      "No of decision Trees : 92\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision Trees :',i)\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52200a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier Algorithm\n",
    "#No of decision Trees=17 gives value of recall 0.63 \n",
    "rfc=RandomForestClassifier(n_estimators=17,random_state=1)\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply max_depth pruning on RandomForestClassifier Algorithm\n",
    "for i in range(1,9):\n",
    "    rfc_max_depth=RandomForestClassifier(n_estimators=17,random_state=1,max_depth=i)\n",
    "    print('Max depth :',i)\n",
    "    rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3367e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth pruning on RandomForestClassifier Algorithm\n",
    "#Max depth = 3 gives best recall 0.83\n",
    "rfc_max_depth=RandomForestClassifier(n_estimators=17,random_state=1,max_depth=3)\n",
    "rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply min_samples_leaf pruning on RandomForestClassifier Algorithm\n",
    "for i in range(45,101):\n",
    "    rfc_min_leaf=RandomForestClassifier(n_estimators=17,random_state=1,min_samples_leaf=i)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_samples_leaf pruning on RandomForestClassifier Algorithm\n",
    "#min_samples_leaf = 52 gives best recall 0.81\n",
    "rfc_min_leaf=RandomForestClassifier(n_estimators=17,random_state=1,min_samples_leaf=52)\n",
    "rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818713e3",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply ADABoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    abc=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of Decision stumps:',i)\n",
    "    abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADABoostClassifier\n",
    "#No of decision stump=6 gives best recall 0.85\n",
    "abc=AdaBoostClassifier(n_estimators=6,random_state=1)\n",
    "abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511999a",
   "metadata": {},
   "source": [
    "# GradientBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cdbc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply GradientBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73d38266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.39      0.32      5398\n",
      "           1       0.98      0.88      0.93      5398\n",
      "           2       0.28      0.54      0.37      5398\n",
      "           3       0.31      0.09      0.14      5398\n",
      "           4       0.32      0.50      0.39      5398\n",
      "           5       0.45      0.55      0.50      5398\n",
      "           6       0.18      0.00      0.01      5398\n",
      "           7       0.52      0.33      0.41      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.38     43184\n",
      "weighted avg       0.41      0.41      0.38     43184\n",
      "\n",
      "[[2098   28 1361   72  999  429    3  408]\n",
      " [ 130 4767   19   39  332   92   18    1]\n",
      " [1021   12 2900  217  193  712   18  325]\n",
      " [ 799    5 1996  475 1139  793   18  173]\n",
      " [1286    4  220  151 2709  702    2  324]\n",
      " [ 193    8  745  347 1023 2964    3  115]\n",
      " [1451   23 1732  134 1435  306   16  301]\n",
      " [ 775    6 1458   86  746  519   11 1797]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.38      0.32      5398\n",
      "           1       0.98      0.88      0.93      5398\n",
      "           2       0.28      0.54      0.37      5398\n",
      "           3       0.25      0.09      0.13      5398\n",
      "           4       0.32      0.49      0.39      5398\n",
      "           5       0.45      0.55      0.50      5398\n",
      "           6       0.18      0.00      0.01      5398\n",
      "           7       0.52      0.33      0.41      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.41      0.41      0.38     43184\n",
      "weighted avg       0.41      0.41      0.38     43184\n",
      "\n",
      "[[2056   27 1365  157  958  428    3  404]\n",
      " [ 147 4767   19   26  328   92   18    1]\n",
      " [1009   12 2916  269  161  712   18  301]\n",
      " [ 837    5 1972  472 1131  791   18  172]\n",
      " [1252    4  221  242 2653  703    2  321]\n",
      " [ 220    8  748  305 1021 2964    3  129]\n",
      " [1402   17 1746  221 1402  307   16  287]\n",
      " [ 713    5 1472  185  710  518   12 1783]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.38      0.32      5398\n",
      "           1       0.98      0.88      0.93      5398\n",
      "           2       0.28      0.54      0.37      5398\n",
      "           3       0.27      0.11      0.16      5398\n",
      "           4       0.32      0.49      0.38      5398\n",
      "           5       0.46      0.55      0.50      5398\n",
      "           6       0.21      0.00      0.01      5398\n",
      "           7       0.53      0.33      0.41      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.38     43184\n",
      "weighted avg       0.42      0.41      0.38     43184\n",
      "\n",
      "[[2037   26 1369  169  963  428    3  403]\n",
      " [ 138 4767   20   36  328   92   16    1]\n",
      " [ 961    8 2908  329  165  711   15  301]\n",
      " [ 794    6 1886  607 1127  792   12  174]\n",
      " [1229    4  221  279 2642  697    2  324]\n",
      " [ 212    8  701  370 1017 2964    2  124]\n",
      " [1384   19 1756  240 1401  306   16  276]\n",
      " [ 691    5 1477  207  703  517    9 1789]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.38      0.32      5398\n",
      "           1       0.98      0.88      0.93      5398\n",
      "           2       0.28      0.54      0.37      5398\n",
      "           3       0.29      0.12      0.17      5398\n",
      "           4       0.32      0.49      0.39      5398\n",
      "           5       0.46      0.55      0.50      5398\n",
      "           6       0.20      0.00      0.01      5398\n",
      "           7       0.52      0.33      0.41      5398\n",
      "\n",
      "    accuracy                           0.41     43184\n",
      "   macro avg       0.42      0.41      0.39     43184\n",
      "weighted avg       0.42      0.41      0.39     43184\n",
      "\n",
      "[[2040   27 1366  156  969  428    7  405]\n",
      " [ 138 4767   20   36  328   92   16    1]\n",
      " [ 964   12 2896  327  170  711   11  307]\n",
      " [ 744   19 1848  671 1144  781   14  177]\n",
      " [1230    3  226  254 2667  693    2  323]\n",
      " [ 183    8  693  415 1013 2953    5  128]\n",
      " [1391   20 1739  231 1413  306   16  282]\n",
      " [ 704    5 1477  190  712  515   10 1785]]\n",
      "No of decision tree: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m gbc\u001b[38;5;241m=\u001b[39mGradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39mi,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo of decision tree:\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m----> 4\u001b[0m gbc\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgbc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(model):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     Y_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X_test1)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(Y_test1,Y_pred))\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    656\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    657\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    658\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    659\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    243\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    245\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 246\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    249\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    250\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    251\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,101):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    gbc=create_model(gbc)#GradientBoostingClassifier\n",
    "#Number of Decision Tree=12\n",
    "gbc=GradientBoostingClassifier(n_estimators=12,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ff07f",
   "metadata": {},
   "source": [
    "# XtremeGradientBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05b2e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply XtremeGradientBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71151701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.38      0.35      5398\n",
      "           1       0.94      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.32      0.24      0.27      5398\n",
      "           4       0.34      0.54      0.41      5398\n",
      "           5       0.47      0.54      0.50      5398\n",
      "           6       0.24      0.02      0.04      5398\n",
      "           7       0.66      0.45      0.54      5398\n",
      "\n",
      "    accuracy                           0.44     43184\n",
      "   macro avg       0.45      0.44      0.42     43184\n",
      "weighted avg       0.45      0.44      0.42     43184\n",
      "\n",
      "[[2067   15 1341  142 1144  293   71  325]\n",
      " [ 172 4417   23  146  481  156    3    0]\n",
      " [ 792   45 2765  556  230  746   76  188]\n",
      " [ 486   70 1267 1300  940 1122   82  131]\n",
      " [1021   13  209  369 2917  435   61  373]\n",
      " [ 100   76  435 1006  768 2925   63   25]\n",
      " [1254   41 1623  397 1461  242  132  248]\n",
      " [ 644    3 1002  161  761  323   54 2450]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.35      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.33      0.26      0.29      5398\n",
      "           4       0.34      0.54      0.42      5398\n",
      "           5       0.47      0.56      0.51      5398\n",
      "           6       0.26      0.02      0.04      5398\n",
      "           7       0.66      0.46      0.54      5398\n",
      "\n",
      "    accuracy                           0.44     43184\n",
      "   macro avg       0.46      0.44      0.43     43184\n",
      "weighted avg       0.46      0.44      0.43     43184\n",
      "\n",
      "[[2038   15 1376  144 1146  290   65  324]\n",
      " [ 148 4425   39  149  477  157    3    0]\n",
      " [ 764   41 2777  581  220  755   62  198]\n",
      " [ 411   68 1254 1426  906 1149   64  120]\n",
      " [ 972   13  247  383 2912  435   63  373]\n",
      " [  86   60  418 1058  674 3020   44   38]\n",
      " [1205   38 1649  433 1457  242  126  248]\n",
      " [ 627    4 1006  163  762  315   49 2472]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.35      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.33      0.26      0.29      5398\n",
      "           4       0.34      0.55      0.42      5398\n",
      "           5       0.47      0.57      0.52      5398\n",
      "           6       0.24      0.02      0.04      5398\n",
      "           7       0.66      0.46      0.54      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.45      0.45      0.43     43184\n",
      "weighted avg       0.45      0.45      0.43     43184\n",
      "\n",
      "[[2062   15 1334  139 1160  293   74  321]\n",
      " [ 148 4425   39  156  477  149    4    0]\n",
      " [ 750   39 2774  584  227  769   62  193]\n",
      " [ 429   66 1256 1392  895 1170   67  123]\n",
      " [ 961   12  234  376 2942  430   77  366]\n",
      " [ 103   64  417 1041  634 3051   50   38]\n",
      " [1221   33 1640  425 1456  254  124  245]\n",
      " [ 641    4 1001  165  758  319   51 2459]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.35      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.33      0.26      0.29      5398\n",
      "           4       0.35      0.55      0.43      5398\n",
      "           5       0.48      0.57      0.52      5398\n",
      "           6       0.25      0.02      0.04      5398\n",
      "           7       0.66      0.46      0.54      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.46      0.45      0.43     43184\n",
      "weighted avg       0.46      0.45      0.43     43184\n",
      "\n",
      "[[2076   14 1327  134 1178  281   70  318]\n",
      " [ 153 4425   36  156  466  158    4    0]\n",
      " [ 738   39 2756  619  227  763   60  196]\n",
      " [ 402   65 1232 1413  878 1212   70  126]\n",
      " [ 953   12  223  373 2975  430   67  365]\n",
      " [ 109   60  401 1024  614 3102   45   43]\n",
      " [1228   32 1632  421 1471  252  121  241]\n",
      " [ 640    3 1002  169  758  315   46 2465]]\n",
      "No of decision tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.38      0.36      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.40      5398\n",
      "           3       0.33      0.27      0.30      5398\n",
      "           4       0.35      0.55      0.43      5398\n",
      "           5       0.48      0.58      0.53      5398\n",
      "           6       0.25      0.02      0.04      5398\n",
      "           7       0.67      0.46      0.54      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.46      0.45      0.43     43184\n",
      "weighted avg       0.46      0.45      0.43     43184\n",
      "\n",
      "[[2069   14 1338  134 1185  271   75  312]\n",
      " [ 153 4425   36  165  464  151    3    1]\n",
      " [ 691   33 2776  646  234  750   75  193]\n",
      " [ 392   64 1231 1476  880 1183   66  106]\n",
      " [ 906   12  234  388 2985  428   77  368]\n",
      " [ 107   59  387 1062  599 3111   47   26]\n",
      " [1192   31 1636  450 1482  243  129  235]\n",
      " [ 628    3 1007  168  772  301   49 2470]]\n",
      "No of decision tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.39      0.36      5398\n",
      "           1       0.95      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.33      0.28      0.30      5398\n",
      "           4       0.35      0.55      0.42      5398\n",
      "           5       0.48      0.58      0.53      5398\n",
      "           6       0.25      0.03      0.05      5398\n",
      "           7       0.67      0.46      0.54      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.46      0.45      0.44     43184\n",
      "weighted avg       0.46      0.45      0.44     43184\n",
      "\n",
      "[[2083   12 1325  143 1174  263   84  314]\n",
      " [ 151 4425   36  169  449  160    7    1]\n",
      " [ 674   27 2750  686  237  752   75  197]\n",
      " [ 387   62 1195 1501  865 1223   63  102]\n",
      " [ 897   12  234  408 2956  431   87  373]\n",
      " [  81   69  398 1047  589 3147   45   22]\n",
      " [1183   30 1629  463 1484  233  140  236]\n",
      " [ 633    5  997  168  766  297   54 2478]]\n",
      "No of decision tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.39      0.36      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.33      0.28      0.30      5398\n",
      "           4       0.35      0.55      0.43      5398\n",
      "           5       0.49      0.59      0.53      5398\n",
      "           6       0.25      0.03      0.05      5398\n",
      "           7       0.67      0.46      0.55      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.46      0.45      0.44     43184\n",
      "weighted avg       0.46      0.45      0.44     43184\n",
      "\n",
      "[[2095   12 1331  144 1167  257   75  317]\n",
      " [ 129 4425   58  166  449  163    7    1]\n",
      " [ 673   29 2752  699  232  741   72  200]\n",
      " [ 381   52 1217 1511  851 1220   68   98]\n",
      " [ 896   12  238  421 2954  433   84  360]\n",
      " [  81   52  389 1041  590 3183   42   20]\n",
      " [1204   30 1624  479 1465  226  135  235]\n",
      " [ 627    5  998  170  746  294   55 2503]]\n",
      "No of decision tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.39      0.37      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.32      0.28      0.30      5398\n",
      "           4       0.35      0.55      0.43      5398\n",
      "           5       0.49      0.59      0.53      5398\n",
      "           6       0.27      0.03      0.05      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.47      0.45      0.44     43184\n",
      "weighted avg       0.47      0.45      0.44     43184\n",
      "\n",
      "[[2101   12 1320  144 1177  250   78  316]\n",
      " [ 125 4425   62  165  447  165    8    1]\n",
      " [ 666   28 2738  710  235  725   83  213]\n",
      " [ 374   50 1230 1512  842 1220   68  102]\n",
      " [ 863   12  251  434 2951  421   91  375]\n",
      " [  80   47  387 1060  585 3177   41   21]\n",
      " [1183   27 1617  496 1451  232  154  238]\n",
      " [ 638    5  976  175  750  292   49 2513]]\n",
      "No of decision tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.39      0.37      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.39      5398\n",
      "           3       0.32      0.28      0.30      5398\n",
      "           4       0.35      0.54      0.43      5398\n",
      "           5       0.49      0.59      0.53      5398\n",
      "           6       0.28      0.03      0.05      5398\n",
      "           7       0.67      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.45     43184\n",
      "   macro avg       0.47      0.45      0.44     43184\n",
      "weighted avg       0.47      0.45      0.44     43184\n",
      "\n",
      "[[2118   12 1344  130 1142  256   78  318]\n",
      " [ 129 4426   60  167  442  166    7    1]\n",
      " [ 664   27 2736  728  226  746   68  203]\n",
      " [ 372   52 1219 1524  837 1238   58   98]\n",
      " [ 877   14  259  437 2914  421  100  376]\n",
      " [  88   53  385 1049  574 3185   41   23]\n",
      " [1180   28 1621  516 1419  236  157  241]\n",
      " [ 640    5  983  181  735  293   43 2518]]\n",
      "No of decision tree: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.40      0.37      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.40      5398\n",
      "           3       0.33      0.29      0.31      5398\n",
      "           4       0.36      0.54      0.43      5398\n",
      "           5       0.49      0.59      0.54      5398\n",
      "           6       0.29      0.04      0.06      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.44     43184\n",
      "weighted avg       0.47      0.46      0.44     43184\n",
      "\n",
      "[[2151   11 1304  128 1130  246  104  324]\n",
      " [ 128 4426   60  168  429  167    7   13]\n",
      " [ 666   22 2751  726  227  712   75  219]\n",
      " [ 375   54 1182 1563  824 1238   66   96]\n",
      " [ 858   14  258  444 2931  421  109  363]\n",
      " [  98   61  385 1036  553 3189   50   26]\n",
      " [1175   25 1596  514 1416  235  196  241]\n",
      " [ 639    5  971  191  736  283   62 2511]]\n",
      "No of decision tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.40      0.37      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.32      0.51      0.40      5398\n",
      "           3       0.32      0.29      0.31      5398\n",
      "           4       0.36      0.55      0.43      5398\n",
      "           5       0.49      0.59      0.53      5398\n",
      "           6       0.29      0.04      0.07      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.44     43184\n",
      "weighted avg       0.47      0.46      0.44     43184\n",
      "\n",
      "[[2159   11 1299  132 1122  237  107  331]\n",
      " [ 127 4423   62  164  443  171    7    1]\n",
      " [ 663   22 2739  738  225  713   84  214]\n",
      " [ 391   49 1170 1557  821 1241   70   99]\n",
      " [ 859   13  249  439 2945  422  112  359]\n",
      " [ 104   58  377 1056  563 3165   52   23]\n",
      " [1166   24 1590  527 1412  232  206  241]\n",
      " [ 652    4  952  192  734  283   65 2516]]\n",
      "No of decision tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.40      0.38      5398\n",
      "           1       0.96      0.83      0.89      5398\n",
      "           2       0.33      0.50      0.40      5398\n",
      "           3       0.32      0.30      0.31      5398\n",
      "           4       0.36      0.54      0.43      5398\n",
      "           5       0.49      0.58      0.53      5398\n",
      "           6       0.30      0.04      0.08      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.45     43184\n",
      "weighted avg       0.47      0.46      0.45     43184\n",
      "\n",
      "[[2170   12 1293  126 1117  235  112  333]\n",
      " [  80 4467   62  176  419  173    8   13]\n",
      " [ 652   22 2709  758  226  710   97  224]\n",
      " [ 381   47 1132 1615  811 1242   73   97]\n",
      " [ 825   17  247  480 2914  421  128  366]\n",
      " [  96   53  367 1109  541 3153   60   19]\n",
      " [1165   23 1550  551 1397  231  232  249]\n",
      " [ 652    5  946  195  715  274   72 2539]]\n",
      "No of decision tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.41      0.38      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.50      0.40      5398\n",
      "           3       0.32      0.31      0.31      5398\n",
      "           4       0.36      0.54      0.43      5398\n",
      "           5       0.50      0.59      0.54      5398\n",
      "           6       0.30      0.05      0.08      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.45     43184\n",
      "weighted avg       0.47      0.46      0.45     43184\n",
      "\n",
      "[[2191   11 1278  124 1113  231  119  331]\n",
      " [ 123 4423   62  178  421  172    6   13]\n",
      " [ 632   21 2704  802  222  687  106  224]\n",
      " [ 374   42 1118 1659  799 1242   69   95]\n",
      " [ 825   17  245  503 2893  417  132  366]\n",
      " [  87   41  360 1116  520 3195   60   19]\n",
      " [1159   23 1525  578 1397  224  243  249]\n",
      " [ 648    5  934  204  716  274   72 2545]]\n",
      "No of decision tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.41      0.38      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.50      0.40      5398\n",
      "           3       0.32      0.31      0.32      5398\n",
      "           4       0.36      0.53      0.43      5398\n",
      "           5       0.50      0.59      0.54      5398\n",
      "           6       0.29      0.05      0.08      5398\n",
      "           7       0.66      0.47      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.45     43184\n",
      "weighted avg       0.47      0.46      0.45     43184\n",
      "\n",
      "[[2200   11 1261  126 1106  227  127  340]\n",
      " [ 123 4421   62  180  422  171    6   13]\n",
      " [ 621   19 2703  812  227  677  110  229]\n",
      " [ 369   42 1086 1676  802 1238   87   98]\n",
      " [ 823   16  236  497 2886  418  147  375]\n",
      " [  88   44  361 1118  527 3179   62   19]\n",
      " [1167   23 1514  583 1382  228  255  246]\n",
      " [ 641    5  927  205  718  270   75 2557]]\n",
      "No of decision tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.38      5398\n",
      "           1       0.96      0.82      0.89      5398\n",
      "           2       0.33      0.50      0.40      5398\n",
      "           3       0.32      0.32      0.32      5398\n",
      "           4       0.36      0.53      0.43      5398\n",
      "           5       0.50      0.59      0.54      5398\n",
      "           6       0.29      0.05      0.08      5398\n",
      "           7       0.66      0.48      0.55      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.47      0.46      0.45     43184\n",
      "weighted avg       0.47      0.46      0.45     43184\n",
      "\n",
      "[[2192   11 1271  127 1110  215  133  339]\n",
      " [ 114 4425   71  186  420  169    2   11]\n",
      " [ 601   20 2701  851  222  668  112  223]\n",
      " [ 360   41 1076 1716  777 1237   92   99]\n",
      " [ 825   15  238  520 2852  418  147  383]\n",
      " [  92   50  375 1122  510 3164   64   21]\n",
      " [1166   23 1502  600 1380  223  255  249]\n",
      " [ 646    5  916  216  702  267   80 2566]]\n",
      "No of decision tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.39      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.50      0.40      5398\n",
      "           3       0.32      0.32      0.32      5398\n",
      "           4       0.36      0.53      0.43      5398\n",
      "           5       0.50      0.60      0.54      5398\n",
      "           6       0.31      0.05      0.09      5398\n",
      "           7       0.66      0.48      0.56      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.48      0.46      0.45     43184\n",
      "weighted avg       0.48      0.46      0.45     43184\n",
      "\n",
      "[[2193   11 1267  122 1113  207  137  348]\n",
      " [ 127 4425   57  183  419  174    2   11]\n",
      " [ 606   20 2674  865  223  672  118  220]\n",
      " [ 359   41 1079 1722  764 1244   90   99]\n",
      " [ 819   15  238  529 2839  421  154  383]\n",
      " [  84   44  383 1096  481 3223   65   22]\n",
      " [1167   23 1476  592 1355  234  294  257]\n",
      " [ 634    5  909  217  694  262   82 2595]]\n",
      "No of decision tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.39      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.49      0.40      5398\n",
      "           3       0.32      0.32      0.32      5398\n",
      "           4       0.36      0.53      0.43      5398\n",
      "           5       0.50      0.60      0.55      5398\n",
      "           6       0.32      0.06      0.10      5398\n",
      "           7       0.66      0.48      0.56      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.48      0.46      0.45     43184\n",
      "weighted avg       0.48      0.46      0.45     43184\n",
      "\n",
      "[[2197   11 1266  123 1106  199  144  352]\n",
      " [ 133 4427   51  180  416  178    2   11]\n",
      " [ 603   21 2670  876  225  660  129  214]\n",
      " [ 352   45 1078 1714  759 1255   97   98]\n",
      " [ 816   14  238  532 2838  421  153  386]\n",
      " [  85   38  396 1093  477 3233   65   11]\n",
      " [1161   22 1470  607 1347  227  311  253]\n",
      " [ 641    5  905  214  692  257   81 2603]]\n",
      "No of decision tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.39      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.49      0.40      5398\n",
      "           3       0.32      0.32      0.32      5398\n",
      "           4       0.36      0.53      0.43      5398\n",
      "           5       0.50      0.60      0.55      5398\n",
      "           6       0.31      0.06      0.10      5398\n",
      "           7       0.66      0.49      0.56      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.48      0.46      0.45     43184\n",
      "weighted avg       0.48      0.46      0.45     43184\n",
      "\n",
      "[[2236   11 1245  123 1095  194  149  345]\n",
      " [ 145 4428   39  186  411  176    2   11]\n",
      " [ 600   19 2660  888  226  649  139  217]\n",
      " [ 347   42 1069 1722  753 1256  109  100]\n",
      " [ 792   15  234  561 2835  414  165  382]\n",
      " [  82   43  388 1114  477 3214   69   11]\n",
      " [1145   21 1462  621 1341  231  322  255]\n",
      " [ 631    5  896  214  690  253   90 2619]]\n",
      "No of decision tree: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.42      0.40      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.49      0.39      5398\n",
      "           3       0.32      0.33      0.32      5398\n",
      "           4       0.36      0.52      0.43      5398\n",
      "           5       0.50      0.59      0.55      5398\n",
      "           6       0.30      0.06      0.10      5398\n",
      "           7       0.66      0.48      0.56      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.48      0.46      0.45     43184\n",
      "weighted avg       0.48      0.46      0.45     43184\n",
      "\n",
      "[[2283   10 1216  120 1085  188  150  346]\n",
      " [ 149 4425   37  200  398  176    2   11]\n",
      " [ 596   20 2619  918  224  653  149  219]\n",
      " [ 341   42 1042 1770  750 1238  104  111]\n",
      " [ 795   15  233  571 2814  412  178  380]\n",
      " [  83   43  385 1119  469 3208   75   16]\n",
      " [1149   22 1451  632 1334  227  330  253]\n",
      " [ 633    5  894  216  695  251   94 2610]]\n",
      "No of decision tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.43      0.40      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.49      0.40      5398\n",
      "           3       0.32      0.33      0.32      5398\n",
      "           4       0.36      0.52      0.43      5398\n",
      "           5       0.50      0.59      0.54      5398\n",
      "           6       0.31      0.06      0.11      5398\n",
      "           7       0.66      0.48      0.56      5398\n",
      "\n",
      "    accuracy                           0.46     43184\n",
      "   macro avg       0.48      0.46      0.46     43184\n",
      "weighted avg       0.48      0.46      0.46     43184\n",
      "\n",
      "[[2300   10 1206  116 1078  190  156  342]\n",
      " [ 152 4423   36  204  400  169    3   11]\n",
      " [ 595   20 2621  906  227  660  152  217]\n",
      " [ 343   39 1038 1762  750 1244  110  112]\n",
      " [ 801   15  235  579 2813  403  174  378]\n",
      " [ 111   42  382 1132  450 3190   74   17]\n",
      " [1153   22 1441  628 1330  227  343  254]\n",
      " [ 635    5  886  220  685  251  102 2614]]\n",
      "No of decision tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.43      0.41      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.48      0.39      5398\n",
      "           3       0.32      0.33      0.32      5398\n",
      "           4       0.37      0.52      0.43      5398\n",
      "           5       0.50      0.59      0.54      5398\n",
      "           6       0.31      0.07      0.11      5398\n",
      "           7       0.67      0.49      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2343   10 1191  111 1052  192  164  335]\n",
      " [ 139 4423   44  211  394  172    4   11]\n",
      " [ 580   20 2584  930  228  667  168  221]\n",
      " [ 336   39 1023 1774  755 1245  112  114]\n",
      " [ 777   15  242  582 2801  407  189  385]\n",
      " [ 104   41  381 1143  425 3207   79   18]\n",
      " [1126   22 1421  635 1330  233  378  253]\n",
      " [ 599    5  877  221  674  252  111 2659]]\n",
      "No of decision tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.42      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.33      0.48      0.39      5398\n",
      "           3       0.32      0.33      0.32      5398\n",
      "           4       0.37      0.52      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.07      0.12      5398\n",
      "           7       0.66      0.49      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2371   10 1150  115 1049  190  171  342]\n",
      " [ 139 4419   45  213  391  172    8   11]\n",
      " [ 568   20 2580  939  230  658  178  225]\n",
      " [ 340   39 1011 1783  741 1240  131  113]\n",
      " [ 760   15  242  596 2786  412  199  388]\n",
      " [ 101   45  384 1139  409 3219   83   18]\n",
      " [1125   22 1417  632 1324  236  388  254]\n",
      " [ 602    5  873  216  676  245  118 2663]]\n",
      "No of decision tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.44      0.42      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.34      0.48      0.40      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.31      0.07      0.12      5398\n",
      "           7       0.67      0.49      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2399   10 1128  111 1043  186  179  342]\n",
      " [ 139 4419   45  214  391  171    8   11]\n",
      " [ 553   20 2587  945  237  649  186  221]\n",
      " [ 321   37 1024 1810  734 1233  129  110]\n",
      " [ 750   16  249  607 2770  412  208  386]\n",
      " [  96   44  387 1130  397 3244   82   18]\n",
      " [1121   22 1396  650 1320  235  399  255]\n",
      " [ 598    5  878  218  668  246  115 2670]]\n",
      "No of decision tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.45      0.42      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.34      0.48      0.40      5398\n",
      "           3       0.32      0.33      0.32      5398\n",
      "           4       0.36      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.31      0.07      0.12      5398\n",
      "           7       0.67      0.49      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2415   10 1111  114 1042  182  180  344]\n",
      " [ 138 4418   46  214  391  172    8   11]\n",
      " [ 552   20 2582  953  237  646  185  223]\n",
      " [ 328   36 1022 1793  738 1237  135  109]\n",
      " [ 751   16  249  607 2758  422  205  390]\n",
      " [  96   48  393 1123  400 3241   80   17]\n",
      " [1120   21 1389  652 1330  239  400  247]\n",
      " [ 604    5  875  224  668  245  110 2667]]\n",
      "No of decision tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.45      0.43      5398\n",
      "           1       0.96      0.82      0.89      5398\n",
      "           2       0.34      0.48      0.39      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.31      0.08      0.12      5398\n",
      "           7       0.67      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2449   10 1095  111 1025  186  171  351]\n",
      " [ 135 4419   46  226  379  170   12   11]\n",
      " [ 537   19 2568  963  238  654  197  222]\n",
      " [ 326   38 1013 1821  719 1234  138  109]\n",
      " [ 743   16  252  613 2743  434  208  389]\n",
      " [ 102   53  393 1122  385 3243   84   16]\n",
      " [1115   21 1374  662 1327  244  411  244]\n",
      " [ 595    5  867  234  666  245  113 2673]]\n",
      "No of decision tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43      5398\n",
      "           1       0.96      0.82      0.89      5398\n",
      "           2       0.34      0.48      0.40      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.08      0.12      5398\n",
      "           7       0.67      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2461   10 1080  103 1036  182  176  350]\n",
      " [ 136 4418   45  224  380  172   12   11]\n",
      " [ 532   19 2574  964  241  652  195  221]\n",
      " [ 327   39 1024 1817  706 1236  137  112]\n",
      " [ 740   16  253  606 2760  437  201  385]\n",
      " [  99   52  397 1121  384 3243   86   16]\n",
      " [1113   21 1368  666 1331  240  408  251]\n",
      " [ 589    5  861  225  665  246  123 2684]]\n",
      "No of decision tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43      5398\n",
      "           1       0.97      0.82      0.89      5398\n",
      "           2       0.34      0.47      0.39      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.61      0.55      5398\n",
      "           6       0.31      0.08      0.12      5398\n",
      "           7       0.67      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.49      0.47      0.46     43184\n",
      "weighted avg       0.49      0.47      0.46     43184\n",
      "\n",
      "[[2478   10 1076  104 1026  178  174  352]\n",
      " [ 139 4417   42  214  379  184   12   11]\n",
      " [ 536   19 2558  969  240  643  208  225]\n",
      " [ 315   37 1027 1830  707 1234  137  111]\n",
      " [ 742   16  252  609 2755  434  208  382]\n",
      " [  90   52  397 1102  382 3278   81   16]\n",
      " [1117   20 1361  669 1326  239  418  248]\n",
      " [ 601    5  857  222  666  245  124 2678]]\n",
      "No of decision tree: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43      5398\n",
      "           1       0.96      0.82      0.89      5398\n",
      "           2       0.34      0.47      0.39      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.08      0.12      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.49      0.47      0.46     43184\n",
      "weighted avg       0.49      0.47      0.46     43184\n",
      "\n",
      "[[2467   10 1067  102 1028  172  195  357]\n",
      " [ 140 4415   44  217  378  183   10   11]\n",
      " [ 541   19 2545  981  242  635  200  235]\n",
      " [ 313   37 1022 1853  707 1214  141  111]\n",
      " [ 736   16  245  606 2766  430  217  382]\n",
      " [  93   57  397 1103  390 3265   78   15]\n",
      " [1118   20 1358  661 1329  239  422  251]\n",
      " [ 593    5  852  229  669  246  130 2674]]\n",
      "No of decision tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.44      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.34      0.47      0.39      5398\n",
      "           3       0.32      0.34      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.08      0.13      5398\n",
      "           7       0.66      0.49      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.46     43184\n",
      "weighted avg       0.48      0.47      0.46     43184\n",
      "\n",
      "[[2494   10 1048  102 1018  167  203  356]\n",
      " [ 128 4416   48  222  385  178   10   11]\n",
      " [ 547   19 2531  979  238  640  209  235]\n",
      " [ 307   37 1013 1849  713 1210  158  111]\n",
      " [ 742   16  246  606 2756  427  227  378]\n",
      " [  95   59  397 1112  389 3248   83   15]\n",
      " [1118   20 1348  661 1322  238  436  255]\n",
      " [ 598    5  841  232  669  244  140 2669]]\n",
      "No of decision tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.44      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.34      0.47      0.39      5398\n",
      "           3       0.32      0.35      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.08      0.13      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.47     43184\n",
      "weighted avg       0.48      0.47      0.47     43184\n",
      "\n",
      "[[2497   10 1048  104 1007  163  204  365]\n",
      " [ 127 4418   48  217  385  180   12   11]\n",
      " [ 548   19 2516  994  235  644  211  231]\n",
      " [ 304   38  995 1873  700 1223  151  114]\n",
      " [ 742   17  247  614 2738  435  231  374]\n",
      " [  93   64  396 1116  381 3246   85   17]\n",
      " [1116   19 1332  682 1313  239  443  254]\n",
      " [ 599    5  834  241  653  243  141 2682]]\n",
      "No of decision tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.47      0.44      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.34      0.46      0.39      5398\n",
      "           3       0.32      0.35      0.34      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.08      0.13      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.49      0.47      0.47     43184\n",
      "weighted avg       0.49      0.47      0.47     43184\n",
      "\n",
      "[[2511   10 1026  104 1005  159  219  364]\n",
      " [ 118 4418   54  220  380  182   15   11]\n",
      " [ 570   19 2506  998  231  645  198  231]\n",
      " [ 307   38  984 1890  690 1218  158  113]\n",
      " [ 742   17  248  611 2740  432  238  370]\n",
      " [  97   64  391 1109  382 3246   91   18]\n",
      " [1126   19 1321  682 1299  237  457  257]\n",
      " [ 602    5  820  241  652  243  152 2683]]\n",
      "No of decision tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.47      0.44      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.34      0.46      0.39      5398\n",
      "           3       0.32      0.35      0.34      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.29      0.09      0.13      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.48      0.47      0.47     43184\n",
      "weighted avg       0.48      0.47      0.47     43184\n",
      "\n",
      "[[2513   10 1000  107 1002  161  234  371]\n",
      " [ 116 4415   54  224  382  182   14   11]\n",
      " [ 569   20 2508  995  224  646  206  230]\n",
      " [ 308   37  985 1893  696 1214  156  109]\n",
      " [ 741   16  249  617 2738  434  239  364]\n",
      " [  96   64  395 1127  379 3229   90   18]\n",
      " [1125   16 1312  691 1297  239  459  259]\n",
      " [ 614    5  802  240  652  245  159 2681]]\n",
      "No of decision tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.34      0.47      0.40      5398\n",
      "           3       0.32      0.35      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.29      0.09      0.13      5398\n",
      "           7       0.67      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.47     43184\n",
      "   macro avg       0.49      0.47      0.47     43184\n",
      "weighted avg       0.49      0.47      0.47     43184\n",
      "\n",
      "[[2538   11  987  107 1001  159  227  368]\n",
      " [ 108 4419   59  231  379  175   16   11]\n",
      " [ 559   21 2513 1001  225  642  209  228]\n",
      " [ 305   42  983 1890  697 1217  154  110]\n",
      " [ 729   18  250  627 2742  420  249  363]\n",
      " [  92   65  388 1136  371 3236   91   19]\n",
      " [1126   16 1310  692 1300  241  460  253]\n",
      " [ 614    6  798  239  655  241  160 2685]]\n",
      "No of decision tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.48      0.45      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.35      0.46      0.40      5398\n",
      "           3       0.32      0.35      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.09      0.14      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.48     43184\n",
      "   macro avg       0.49      0.48      0.47     43184\n",
      "weighted avg       0.49      0.48      0.47     43184\n",
      "\n",
      "[[2567   11  957  110  987  155  231  380]\n",
      " [ 109 4421   58  223  377  181   18   11]\n",
      " [ 564   21 2497 1000  228  644  213  231]\n",
      " [ 310   41  976 1892  692 1217  160  110]\n",
      " [ 726   18  247  617 2750  431  250  359]\n",
      " [ 101   65  388 1129  376 3225   95   19]\n",
      " [1141   17 1301  694 1275  246  475  249]\n",
      " [ 620    6  796  236  649  242  163 2686]]\n",
      "No of decision tree: 44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m xgb\u001b[38;5;241m=\u001b[39mXGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39mi,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo of decision tree:\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m----> 4\u001b[0m xgb\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(model):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     Y_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X_test1)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(Y_test1,Y_pred))\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\chauh\\anaconda3\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    xgb=XGBClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e47eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.48      0.45      5398\n",
      "           1       0.96      0.82      0.88      5398\n",
      "           2       0.35      0.46      0.40      5398\n",
      "           3       0.32      0.35      0.33      5398\n",
      "           4       0.37      0.51      0.43      5398\n",
      "           5       0.51      0.60      0.55      5398\n",
      "           6       0.30      0.09      0.14      5398\n",
      "           7       0.66      0.50      0.57      5398\n",
      "\n",
      "    accuracy                           0.48     43184\n",
      "   macro avg       0.49      0.48      0.47     43184\n",
      "weighted avg       0.49      0.48      0.47     43184\n",
      "\n",
      "[[2567   11  957  110  987  155  231  380]\n",
      " [ 109 4421   58  223  377  181   18   11]\n",
      " [ 564   21 2497 1000  228  644  213  231]\n",
      " [ 310   41  976 1892  692 1217  160  110]\n",
      " [ 726   18  247  617 2750  431  250  359]\n",
      " [ 101   65  388 1129  376 3225   95   19]\n",
      " [1141   17 1301  694 1275  246  475  249]\n",
      " [ 620    6  796  236  649  242  163 2686]]\n"
     ]
    }
   ],
   "source": [
    "#XtremeGradientBoostClassifier\n",
    "#Number of Decision Tree=12\n",
    "xgb=XGBClassifier(n_estimators=43,random_state=1)\n",
    "xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d978a8",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Support Vector Machine algorithm with hard margin\n",
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC(random_state=1)\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea54891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Support Vector Machine algorithm with soft margin\n",
    "svc1=LinearSVC(random_state=1,C=0.9)\n",
    "svc1=create_model(svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ba073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Support Vector Machine algorithm with soft margin\n",
    "svc1=LinearSVC(random_state=1,C=0.9)\n",
    "svc1=create_model(svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754283d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Support Vector Machine algorithm for non linear data with radial basis kernel function\n",
    "r_svc=SVC(random_state=1,kernel='rbf')\n",
    "r_svc=create_model(r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8baafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd311e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note - \n",
    "\n",
    "From Extreme Gradient Boosting(XGB) we found and an accuracy of 48% \n",
    "so, this is the best model for the dataset \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94763ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4. Write a ML/DL program which takes the data as input and predicts the most probable peril even which can happen in next year. \n",
    "The model should come with proper accuracy assessment of the model.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Conclusion :-\n",
    "\n",
    "The most probable peril even which can happen in next year Would be from as the accuracy percentage has as an 88% chances\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
